{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-21 21:34:45.589817: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-09-21 21:34:45.590333: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-09-21 21:34:45.590342: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import datetime\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# CV\n",
    "from PIL import Image\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import MetricCollection, MeanSquaredError\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('/kaggle')\n",
    "from utils.metric import compute_comptetition_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = f\"\"\"\n",
    "execution:\n",
    "    exp_id: exp_010\n",
    "    debug: False\n",
    "    submit: False\n",
    "\n",
    "dataset: \n",
    "    competition_dir: /kaggle/input/child-mind-institute-detect-sleep-states\n",
    "    cv_split_path: /kaggle/input/cv_split/train_folds.csv\n",
    "    train_base_path: /kaggle/input/train_base/train_base.csv\n",
    "    day_csv_dir: /kaggle/input/save_day_csv/day_csvs\n",
    "    \n",
    "seed: 46\n",
    "n_fold: 5\n",
    "\"\"\"\n",
    "\n",
    "CFG = yaml.load(config, Loader=yaml.SafeLoader)\n",
    "\n",
    "CFG[\"output_dir\"] = f\"/kaggle/output/{CFG['execution']['exp_id']}\"\n",
    "os.makedirs(CFG[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "CFG[\"CACHE\"] = {}\n",
    "\n",
    "random.seed(CFG[\"seed\"])\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(CFG[\"seed\"])\n",
    "np.random.seed(CFG[\"seed\"])\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 13\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>target_type</th>\n",
       "      <th>target_step</th>\n",
       "      <th>target_timestamp</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>target</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>2018-08-13 23:00:00+00:00</td>\n",
       "      <td>2018-08-14 22:59:59+00:00</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.915524</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>2018-08-14 23:00:00+00:00</td>\n",
       "      <td>2018-08-15 22:59:59+00:00</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>10932.0</td>\n",
       "      <td>2018-08-15 10:41:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.316667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>2018-08-15 23:00:00+00:00</td>\n",
       "      <td>2018-08-16 22:59:59+00:00</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>27492.0</td>\n",
       "      <td>2018-08-16 09:41:00+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.316667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>2018-08-16 23:00:00+00:00</td>\n",
       "      <td>2018-08-17 22:59:59+00:00</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>44400.0</td>\n",
       "      <td>2018-08-17 09:10:00+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.833333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>2018-08-17 23:00:00+00:00</td>\n",
       "      <td>2018-08-18 22:59:59+00:00</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>62856.0</td>\n",
       "      <td>2018-08-18 10:48:00+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      series_id                start_time                  end_time  \\\n",
       "0  038441c925bb 2018-08-13 23:00:00+00:00 2018-08-14 22:59:59+00:00   \n",
       "1  038441c925bb 2018-08-14 23:00:00+00:00 2018-08-15 22:59:59+00:00   \n",
       "2  038441c925bb 2018-08-15 23:00:00+00:00 2018-08-16 22:59:59+00:00   \n",
       "3  038441c925bb 2018-08-16 23:00:00+00:00 2018-08-17 22:59:59+00:00   \n",
       "4  038441c925bb 2018-08-17 23:00:00+00:00 2018-08-18 22:59:59+00:00   \n",
       "\n",
       "  target_type  target_step           target_timestamp  sample_id    target  \\\n",
       "0      wakeup          NaN                        NaN          0  0.915524   \n",
       "1      wakeup      10932.0  2018-08-15 10:41:00+00:00          1 -0.316667   \n",
       "2      wakeup      27492.0  2018-08-16 09:41:00+00:00          2 -1.316667   \n",
       "3      wakeup      44400.0  2018-08-17 09:10:00+00:00          3 -1.833333   \n",
       "4      wakeup      62856.0  2018-08-18 10:48:00+00:00          4 -0.200000   \n",
       "\n",
       "   fold  \n",
       "0     2  \n",
       "1     2  \n",
       "2     2  \n",
       "3     2  \n",
       "4     2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base df\n",
    "train_base = pd.read_csv(CFG['dataset']['train_base_path'])\n",
    "train_base[\"start_time\"] = pd.to_datetime(train_base[\"start_time\"], utc=True)\n",
    "train_base[\"end_time\"] = pd.to_datetime(train_base[\"end_time\"], utc=True)\n",
    "\n",
    "# cv split\n",
    "cv_split = pd.read_csv(CFG['dataset']['cv_split_path'])\n",
    "train_base = train_base.merge(cv_split, on=\"series_id\", how=\"left\")\n",
    "\n",
    "# label\n",
    "labels = pd.read_csv(f\"{CFG['dataset']['competition_dir']}/train_events.csv\").dropna().reset_index(drop=True)\n",
    "\n",
    "# デバッグ時はデータ数を減らす\n",
    "if CFG['execution']['debug']:\n",
    "    sample_series_id = random.sample(list(train_base[\"series_id\"].unique()), 20)\n",
    "    train_base = train_base[train_base[\"series_id\"].isin(sample_series_id)].reset_index(drop=True)\n",
    "    labels = labels[labels[\"series_id\"].isin(sample_series_id)].reset_index(drop=True)\n",
    "\n",
    "# 目的変数の欠損は平均値で埋める(TODO: ここは分類問題で弾く)\n",
    "train_base[\"target\"] = train_base[\"target\"].fillna(train_base[\"target\"].mean())\n",
    "\n",
    "# 時間単位にする\n",
    "train_base[\"target\"] = train_base[\"target\"] / (60 * 60 // 5) - 12\n",
    "\n",
    "train_base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(series_id, sample_id):\n",
    "    id = f\"{series_id}_{sample_id}\"\n",
    "    if id in CFG[\"CACHE\"]:\n",
    "        df = CFG[\"CACHE\"][id]\n",
    "        return df\n",
    "\n",
    "    train = pd.read_csv(f\"{CFG['dataset']['day_csv_dir']}/{series_id}/{sample_id}.csv\")\n",
    "\n",
    "    if len(train) == 0:\n",
    "        n = int(60 * 60 * 24 // 5)\n",
    "        train = pd.DataFrame({\n",
    "            \"step\": range(n),\n",
    "            \"anglez\": np.zeros(n),\n",
    "            \"enmo\": np.zeros(n),\n",
    "            \"mask\": np.zeros(n),\n",
    "            \"for_wakeup\": np.zeros(n),\n",
    "        })\n",
    "        train = train[[\"step\", \"for_wakeup\", \"anglez\", \"enmo\"]].groupby(train[\"step\"] // 100).mean()\n",
    "        CFG[\"CACHE\"][id] = train\n",
    "        return train\n",
    "\n",
    "    # wakeup or onset\n",
    "    train[\"for_wakeup\"] = float(train[\"target_type\"].values[0] == \"wakeup\")\n",
    "\n",
    "    # 開始時刻のギャップ\n",
    "    train[\"step_diff_start\"] = (pd.to_datetime(train[\"timestamp\"][0]) - pd.to_datetime(train[\"start_time\"][0])).total_seconds() // 5\n",
    "    train[\"step_diff_end\"] = (pd.to_datetime(train[\"end_time\"].values[-1]) - pd.to_datetime(train[\"timestamp\"].values[-1])).total_seconds() // 5\n",
    "\n",
    "    # stepを統一する\n",
    "    train = train.reset_index(drop=True)\n",
    "    train[\"step\"] = (train[\"step_diff_start\"] + train.index).astype(int)\n",
    "    train[\"mask\"] = 1\n",
    "\n",
    "    # padding\n",
    "    head = pd.DataFrame({\"step\": range(int(train[\"step_diff_start\"].values[0]))})\n",
    "    tail = pd.DataFrame({\"step\": range(train[\"step\"].values[-1] + 1, train[\"step\"].values[-1] + int(train[\"step_diff_end\"].values[0]) + 1)})\n",
    "    train = pd.concat([head, train, tail]).reset_index(drop=True)\n",
    "\n",
    "    # fillna\n",
    "    train = train.fillna(0)\n",
    "\n",
    "    train = train[[\"step\", \"for_wakeup\", \"anglez\", \"enmo\"]].groupby(train[\"step\"] // 100).mean()\n",
    "\n",
    "    CFG[\"CACHE\"][id] = train\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, train_base: pd.DataFrame, train_or_test=\"train\"):\n",
    "        self.train_or_test = train_or_test\n",
    "        self.train_base = train_base\n",
    "\n",
    "        self.series_ids = train_base[\"series_id\"].values\n",
    "        self.sample_ids = train_base[\"sample_id\"].values\n",
    "        self.targets = np.array(train_base[\"target\"]).astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.series_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        series_id = self.series_ids[index]\n",
    "        sample_id = self.sample_ids[index]\n",
    "        target = self.targets[index]\n",
    "\n",
    "        df = generate_features(series_id, sample_id)\n",
    "        X = df[[\"step\", \"anglez\", \"enmo\", \"for_wakeup\"]].values.astype(np.float32)\n",
    "\n",
    "        return X, target\n",
    "\n",
    "class LightningDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_dataset=None, valid_dataset=None, \n",
    "                 test_dataset=None, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.valid_dataset = valid_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "                    self.train_dataset, batch_size=self.batch_size, shuffle=True, \n",
    "                    pin_memory=True, worker_init_fn=self.worker_init_fn, num_workers=2)\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "                    self.valid_dataset, batch_size=self.batch_size, shuffle=False, \n",
    "                    pin_memory=True, worker_init_fn=self.worker_init_fn, num_workers=2)\n",
    "        \n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "                    self.test_dataset, batch_size=self.batch_size, shuffle=False, \n",
    "                    pin_memory=True, worker_init_fn=self.worker_init_fn, num_workers=2)\n",
    "        \n",
    "    def worker_init_fn(self, worker_id):                                                 \n",
    "        # dataloaderでnum_workers>1の時の乱数設定\n",
    "        # これを指定しないと各workerのrandom_stateが同じになり、データも同じになる。         \n",
    "        np.random.seed(np.random.get_state()[1][0] + worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 4.9500000e+01,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.4950000e+02,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.4950000e+02,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 3.4950000e+02,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 4.4950000e+02,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 5.4950000e+02,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 6.4950000e+02,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 7.4950000e+02,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.4950000e+02,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.4950000e+02,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.0495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.1495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.2495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.3495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.4495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.5495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.6495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.7495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.8495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.9495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.0495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.1495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.2495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.3495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.4495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.5495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.6495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.7495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.8495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.9495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 3.0495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 3.1495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 3.2495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 3.3495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 3.4495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 3.5495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 3.6495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 3.7495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 3.8495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 3.9495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 4.0495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 4.1495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 4.2495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 4.3495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 4.4495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 4.5495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 4.6495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 4.7495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 4.8495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 4.9495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 5.0495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 5.1495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 5.2495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 5.3495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 5.4495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 5.5495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 5.6495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 5.7495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 5.8495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 5.9495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 6.0495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 6.1495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 6.2495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 6.3495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 6.4495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 6.5495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 6.6495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 6.7495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 6.8495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 6.9495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 7.0495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 7.1495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 7.2495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 7.3495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 7.4495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 7.5495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 7.6495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 7.7495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 7.8495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 7.9495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.0495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.1495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.2495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.3495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.4495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.5495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.6495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.7495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.8495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.9495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.0495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.1495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.2495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.3495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.4495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.5495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.6495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.7495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.8495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.9495000e+03,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.0049500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.0149500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.0249500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.0349500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.0449500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.0549500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.0649500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.0749500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.0849500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.0949500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.1049500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.1149500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.1249500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.1349500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.1449500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.1549500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.1649500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.1749500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.1849500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.1949500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.2049500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.2149500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.2249500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.2349500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.2449500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.2549500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.2649500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.2749500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.2849500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.2949500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.3049500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.3149500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.3249500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.3349500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.3449500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.3549500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.3649500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.3749500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.3849500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.3949500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.4049500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.4149500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.4249500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.4349500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.4449500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.4549500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.4649500e+04,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.4749500e+04, -5.1078682e+00,  7.6810000e-03,  4.0000001e-01],\n",
       "        [ 1.4849500e+04, -8.0069504e+01,  1.3248000e-02,  1.0000000e+00],\n",
       "        [ 1.4949500e+04, -8.0063698e+01,  1.4372000e-02,  1.0000000e+00],\n",
       "        [ 1.5049500e+04, -8.2965889e+01,  1.5366000e-02,  1.0000000e+00],\n",
       "        [ 1.5149500e+04, -8.3044167e+01,  1.5125000e-02,  1.0000000e+00],\n",
       "        [ 1.5249500e+04, -8.3036072e+01,  1.7485000e-02,  1.0000000e+00],\n",
       "        [ 1.5349500e+04, -7.6299980e+01,  2.2732001e-02,  1.0000000e+00],\n",
       "        [ 1.5449500e+04, -4.1568665e+01,  5.0694000e-02,  1.0000000e+00],\n",
       "        [ 1.5549500e+04, -2.0586048e+01,  7.0276000e-02,  1.0000000e+00],\n",
       "        [ 1.5649500e+04, -7.3685389e+00,  2.0164999e-01,  1.0000000e+00],\n",
       "        [ 1.5749500e+04, -1.3153867e+01,  1.5558100e-01,  1.0000000e+00],\n",
       "        [ 1.5849500e+04,  2.4201792e+01,  8.3228998e-02,  1.0000000e+00],\n",
       "        [ 1.5949500e+04, -5.5674758e+00,  9.7191997e-02,  1.0000000e+00],\n",
       "        [ 1.6049500e+04, -6.5970330e+00,  1.0244700e-01,  1.0000000e+00],\n",
       "        [ 1.6149500e+04, -8.9910355e+00,  1.2905499e-01,  1.0000000e+00],\n",
       "        [ 1.6249500e+04, -5.3669682e+00,  1.7922400e-01,  1.0000000e+00],\n",
       "        [ 1.6349500e+04, -1.0709437e+01,  2.0755801e-01,  1.0000000e+00],\n",
       "        [ 1.6449500e+04, -4.0179497e+01,  6.3936003e-02,  1.0000000e+00],\n",
       "        [ 1.6549500e+04, -3.5656750e+00,  5.6363001e-02,  1.0000000e+00],\n",
       "        [ 1.6649500e+04, -1.0359710e+01,  4.6879999e-02,  1.0000000e+00],\n",
       "        [ 1.6749500e+04, -8.2934723e+00,  6.5362997e-02,  1.0000000e+00],\n",
       "        [ 1.6849500e+04, -1.5377110e+00,  1.3793699e-01,  1.0000000e+00],\n",
       "        [ 1.6949500e+04, -1.1801311e+01,  4.9162999e-02,  1.0000000e+00],\n",
       "        [ 1.7049500e+04, -1.4220517e+01,  4.8792999e-02,  1.0000000e+00],\n",
       "        [ 1.7149500e+04,  5.3732872e+00,  4.8195999e-02,  1.0000000e+00],\n",
       "        [ 1.7239500e+04, -8.5875196e+00,  6.8246253e-02,  1.0000000e+00]],\n",
       "       dtype=float32),\n",
       " 0.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = MyDataset(train_base, train_or_test=\"train\")\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15406/15406 [09:32<00:00, 26.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# cache\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    _ = dataset[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningModel(pl.LightningModule):\n",
    "    def __init__(self, loss_fn=nn.CrossEntropyLoss(), lr=0.001, weight_decay=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 数値特徴量とくっつけて、lstmに入力する\n",
    "        dim_feature = 4\n",
    "        hidden_size = 32\n",
    "        self.layer_norm_input = nn.LayerNorm(dim_feature)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=dim_feature,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=2,\n",
    "            dropout=0.0,\n",
    "            batch_first=True,\n",
    "            bidirectional=True)\n",
    "\n",
    "        # 各stepの出力(特徴量の次元)を1次元にする\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.0),\n",
    "            nn.Linear(hidden_size, 1))\n",
    "\n",
    "        self.loss_fn = loss_fn\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        self.train_metrics = MetricCollection([MeanSquaredError()], prefix=\"\")\n",
    "        self.valid_metrics = MetricCollection([MeanSquaredError()], prefix=\"val_\")\n",
    "        \n",
    "        self.val_step_outputs = []\n",
    "        self.val_step_labels = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        # layer norm\n",
    "        # x = self.layer_norm_input(x)\n",
    "\n",
    "        x, _ = self.lstm(x) # -> [bs, n_step, dim_feature]\n",
    "\n",
    "        x = x[:, -1, :] # -> [bs, dim_feature]\n",
    "        x = self.head(x) # -> [bs, 1]\n",
    "        x = x.squeeze(1) # -> [bs]\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        y = torch.flatten(y) # [bs * n_step]\n",
    "        preds = self.forward(X)\n",
    "\n",
    "        loss = self.loss_fn(preds, y)\n",
    "\n",
    "        self.train_metrics(preds, y)\n",
    "        self.log(\"loss\", loss, prog_bar=True, logger=True, on_epoch=True, on_step=True,)\n",
    "        self.log_dict(self.train_metrics, prog_bar=True, logger=True, on_epoch=True, on_step=True,)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        y = torch.flatten(y) # [bs * n_step]\n",
    "        preds = self.forward(X)\n",
    "        \n",
    "        self.val_step_outputs.append(preds)\n",
    "        self.val_step_labels.append(y)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        preds = torch.cat(self.val_step_outputs)\n",
    "        labels = torch.cat(self.val_step_labels)\n",
    "        self.val_step_outputs.clear()\n",
    "        self.val_step_labels.clear()\n",
    "        loss = self.loss_fn(preds, labels)\n",
    "\n",
    "        self.valid_metrics(preds, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=False, logger=True, on_epoch=True, on_step=False,)\n",
    "        self.log_dict(self.valid_metrics, prog_bar=False, logger=True, on_epoch=True, on_step=False,)\n",
    "\n",
    "        # ログをprint\n",
    "        self.print_metric(preds, labels, \"valid\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=3, verbose=True)\n",
    "        return {\"optimizer\": optimizer, \n",
    "                \"lr_scheduler\": scheduler, \n",
    "                \"monitor\": \"val_loss\"}\n",
    "                \n",
    "    def print_metric(self, y_hat, y, train_or_valid=\"train\"):\n",
    "        \"\"\"\n",
    "        ログをprintする。次のepochが終わると上書きされてしまうので。\n",
    "        TODO: たぶんもっとマシな方法があるので探す。\n",
    "        \"\"\"\n",
    "        if train_or_valid == \"train\":\n",
    "            metrics = self.train_metrics\n",
    "        else:\n",
    "            metrics = self.valid_metrics\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "\n",
    "        print(f\"[epoch {self.trainer.current_epoch}] {train_or_valid}: \", end=\"\")\n",
    "        print(f\"{type(self.loss_fn).__name__}={loss:.4f}\", end=\", \")\n",
    "        for name in metrics:\n",
    "            v = metrics[name](y_hat, y)\n",
    "            print(f\"{name}={v:.4f}\", end=\", \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fold 0 ==\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0bf81f5be2747be9b0e3286d9f4114c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] valid: MSELoss=0.0017, MeanSquaredError=0.0017, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4aa9832907b49bab85349eae0261255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7ba6a181304ee6bfafa8817664df9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] valid: MSELoss=0.0002, MeanSquaredError=0.0002, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3837f40d2f46b0a12ffd0e263a61f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] valid: MSELoss=0.0000, MeanSquaredError=0.0000, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60dca4e8cbff49609de9930886e444a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] valid: MSELoss=0.0000, MeanSquaredError=0.0000, \n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "sample_ids = []\n",
    "for fold in range(CFG[\"n_fold\"]):\n",
    "    print(f\"== fold {fold} ==\")\n",
    "    \n",
    "    # 学習・評価データ\n",
    "    train_dataset = MyDataset(train_base[train_base[\"fold\"]!=fold], train_or_test=\"train\")\n",
    "    valid_dataset = MyDataset(train_base[train_base[\"fold\"]==fold], train_or_test=\"train\")\n",
    "    data_module = LightningDataModule(train_dataset, valid_dataset, batch_size=128)\n",
    "\n",
    "    # モデル\n",
    "    model = LightningModel(lr=0.00001, loss_fn=nn.MSELoss())\n",
    "    \n",
    "    # コールバック\n",
    "    cp_callback = ModelCheckpoint(\n",
    "        \"logs/\", \n",
    "        filename=f\"best_model_fold{fold}\",\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=1,\n",
    "        save_last=False,\n",
    "    )\n",
    "    es_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        patience=5,\n",
    "    )\n",
    "\n",
    "    # 学習\n",
    "    trainer = pl.Trainer(\n",
    "        callbacks=[cp_callback, es_callback],\n",
    "        )\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "    # 推論\n",
    "    model = LightningModel.load_from_checkpoint(f\"logs/best_model_fold{fold}.ckpt\", lr=0.001, loss_fn=nn.BCEWithLogitsLoss()).to(\"cuda\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_module.val_dataloader():\n",
    "            pred = model(X.to(\"cuda\")).detach().cpu().numpy()\n",
    "            preds.append(pred)\n",
    "        sample_ids.append(valid_dataset.sample_ids)\n",
    "    break\n",
    "oof = np.concatenate(preds)\n",
    "sample_ids = np.concatenate(sample_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset.train_base[\"oof\"] = oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>target_type</th>\n",
       "      <th>target_step</th>\n",
       "      <th>target_timestamp</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>target</th>\n",
       "      <th>fold</th>\n",
       "      <th>oof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>05e1944c3818</td>\n",
       "      <td>2018-11-15 23:00:00+00:00</td>\n",
       "      <td>2018-11-16 22:59:59+00:00</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129</td>\n",
       "      <td>0.915524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>05e1944c3818</td>\n",
       "      <td>2018-11-16 23:00:00+00:00</td>\n",
       "      <td>2018-11-17 22:59:59+00:00</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130</td>\n",
       "      <td>0.915524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.770184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>05e1944c3818</td>\n",
       "      <td>2018-11-17 23:00:00+00:00</td>\n",
       "      <td>2018-11-18 22:59:59+00:00</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>27360.0</td>\n",
       "      <td>2018-11-18 13:00:00+00:00</td>\n",
       "      <td>131</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.817831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>05e1944c3818</td>\n",
       "      <td>2018-11-18 23:00:00+00:00</td>\n",
       "      <td>2018-11-19 22:59:59+00:00</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>45408.0</td>\n",
       "      <td>2018-11-19 14:04:00+00:00</td>\n",
       "      <td>132</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.836857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>05e1944c3818</td>\n",
       "      <td>2018-11-19 23:00:00+00:00</td>\n",
       "      <td>2018-11-20 22:59:59+00:00</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>61272.0</td>\n",
       "      <td>2018-11-20 12:06:00+00:00</td>\n",
       "      <td>133</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.820472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15328</th>\n",
       "      <td>fbf33b1a2c10</td>\n",
       "      <td>2018-04-19 14:00:00+00:00</td>\n",
       "      <td>2018-04-20 13:59:59+00:00</td>\n",
       "      <td>onset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15328</td>\n",
       "      <td>0.915524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15329</th>\n",
       "      <td>fbf33b1a2c10</td>\n",
       "      <td>2018-04-20 14:00:00+00:00</td>\n",
       "      <td>2018-04-21 13:59:59+00:00</td>\n",
       "      <td>onset</td>\n",
       "      <td>385476.0</td>\n",
       "      <td>2018-04-21 03:38:00+00:00</td>\n",
       "      <td>15329</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.811273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15330</th>\n",
       "      <td>fbf33b1a2c10</td>\n",
       "      <td>2018-04-21 14:00:00+00:00</td>\n",
       "      <td>2018-04-22 13:59:59+00:00</td>\n",
       "      <td>onset</td>\n",
       "      <td>404316.0</td>\n",
       "      <td>2018-04-22 05:48:00+00:00</td>\n",
       "      <td>15330</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.836111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15331</th>\n",
       "      <td>fbf33b1a2c10</td>\n",
       "      <td>2018-04-22 14:00:00+00:00</td>\n",
       "      <td>2018-04-23 13:59:59+00:00</td>\n",
       "      <td>onset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15331</td>\n",
       "      <td>0.915524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.811947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15332</th>\n",
       "      <td>fbf33b1a2c10</td>\n",
       "      <td>2018-04-23 14:00:00+00:00</td>\n",
       "      <td>2018-04-24 13:59:59+00:00</td>\n",
       "      <td>onset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15332</td>\n",
       "      <td>0.915524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3132 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          series_id                start_time                  end_time  \\\n",
       "129    05e1944c3818 2018-11-15 23:00:00+00:00 2018-11-16 22:59:59+00:00   \n",
       "130    05e1944c3818 2018-11-16 23:00:00+00:00 2018-11-17 22:59:59+00:00   \n",
       "131    05e1944c3818 2018-11-17 23:00:00+00:00 2018-11-18 22:59:59+00:00   \n",
       "132    05e1944c3818 2018-11-18 23:00:00+00:00 2018-11-19 22:59:59+00:00   \n",
       "133    05e1944c3818 2018-11-19 23:00:00+00:00 2018-11-20 22:59:59+00:00   \n",
       "...             ...                       ...                       ...   \n",
       "15328  fbf33b1a2c10 2018-04-19 14:00:00+00:00 2018-04-20 13:59:59+00:00   \n",
       "15329  fbf33b1a2c10 2018-04-20 14:00:00+00:00 2018-04-21 13:59:59+00:00   \n",
       "15330  fbf33b1a2c10 2018-04-21 14:00:00+00:00 2018-04-22 13:59:59+00:00   \n",
       "15331  fbf33b1a2c10 2018-04-22 14:00:00+00:00 2018-04-23 13:59:59+00:00   \n",
       "15332  fbf33b1a2c10 2018-04-23 14:00:00+00:00 2018-04-24 13:59:59+00:00   \n",
       "\n",
       "      target_type  target_step           target_timestamp  sample_id  \\\n",
       "129        wakeup          NaN                        NaN        129   \n",
       "130        wakeup          NaN                        NaN        130   \n",
       "131        wakeup      27360.0  2018-11-18 13:00:00+00:00        131   \n",
       "132        wakeup      45408.0  2018-11-19 14:04:00+00:00        132   \n",
       "133        wakeup      61272.0  2018-11-20 12:06:00+00:00        133   \n",
       "...           ...          ...                        ...        ...   \n",
       "15328       onset          NaN                        NaN      15328   \n",
       "15329       onset     385476.0  2018-04-21 03:38:00+00:00      15329   \n",
       "15330       onset     404316.0  2018-04-22 05:48:00+00:00      15330   \n",
       "15331       onset          NaN                        NaN      15331   \n",
       "15332       onset          NaN                        NaN      15332   \n",
       "\n",
       "         target  fold       oof  \n",
       "129    0.915524     0  0.812664  \n",
       "130    0.915524     0  0.770184  \n",
       "131    2.000000     0  0.817831  \n",
       "132    3.066667     0  0.836857  \n",
       "133    1.100000     0  0.820472  \n",
       "...         ...   ...       ...  \n",
       "15328  0.915524     0  0.769057  \n",
       "15329  1.633333     0  0.811273  \n",
       "15330  3.800000     0  0.836111  \n",
       "15331  0.915524     0  0.811947  \n",
       "15332  0.915524     0  0.812664  \n",
       "\n",
       "[3132 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset.train_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8090021320307631"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset.train_base[\"target\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/kaggle/model/lstm/day_regression/train.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6b6167676c655c5c6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d737461746573222c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6b6167676c652f6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d7374617465732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/kaggle/model/lstm/day_regression/train.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train[\u001b[39m\"\u001b[39m\u001b[39mpred_timestamp\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(train[\u001b[39m\"\u001b[39m\u001b[39mstart_time\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m+\u001b[39m pd\u001b[39m.\u001b[39mto_timedelta(train[\u001b[39m\"\u001b[39m\u001b[39moof\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m5\u001b[39m, unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6b6167676c655c5c6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d737461746573222c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6b6167676c652f6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d7374617465732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/kaggle/model/lstm/day_regression/train.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m train \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39mdropna()\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6b6167676c655c5c6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d737461746573222c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6b6167676c652f6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d7374617465732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/kaggle/model/lstm/day_regression/train.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m train[\u001b[39m\"\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (train[\u001b[39m\"\u001b[39m\u001b[39mpred_timestamp\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m-\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(train[\u001b[39m\"\u001b[39m\u001b[39mglobal_start_time\u001b[39m\u001b[39m\"\u001b[39m]))\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mtotal_seconds() \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m5\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train[\"pred_timestamp\"] = pd.to_datetime(train[\"start_time\"]) + pd.to_timedelta(train[\"oof\"] * 5, unit=\"s\")\n",
    "train = train.dropna()\n",
    "\n",
    "train[\"step\"] = (train[\"pred_timestamp\"] - pd.to_datetime(train[\"global_start_time\"])).dt.total_seconds() // 5\n",
    "train[\"score\"] = 1\n",
    "train[\"event\"] = train[\"target_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12651419265452832"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, ap_table = compute_comptetition_metric(labels, train)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train[\"oof\"], bins=np.linspace(0, 60 * 60 * 24 // 5, 50), alpha=0.5)\n",
    "plt.hist(train[\"target\"], bins=np.linspace(0, 60 * 60 * 24 // 5, 50), alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
