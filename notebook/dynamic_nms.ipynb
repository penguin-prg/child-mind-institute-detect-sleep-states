{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 14:00:34.930876: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-06 14:00:34.997487: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-06 14:00:35.441542: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-10-06 14:00:35.441620: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-10-06 14:00:35.441626: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_075\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('/kaggle/src')\n",
    "from utils.xgb import fit_xgb\n",
    "from utils.metric import compute_comptetition_metric\n",
    "from utils.postprocess import post_process\n",
    "from utils.set_seed import seed_base\n",
    "from feature_engineering.ranker import generate_ranker_features\n",
    "\n",
    "PACKAGE_DIR = Path(\"/kaggle/src\")\n",
    "CFG = yaml.safe_load(open(PACKAGE_DIR / \"config.yaml\", \"r\"))\n",
    "print(CFG[\"ranker\"][\"execution\"][\"exp_id\"])\n",
    "\n",
    "CFG[\"output_dir\"] = f\"/kaggle/output/{CFG['ranker']['execution']['exp_id']}\"\n",
    "seed_base(CFG[\"env\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>key_step</th>\n",
       "      <th>step</th>\n",
       "      <th>event</th>\n",
       "      <th>level</th>\n",
       "      <th>series_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039067</td>\n",
       "      <td>4331.5</td>\n",
       "      <td>4275</td>\n",
       "      <td>onset</td>\n",
       "      <td>13.0</td>\n",
       "      <td>038441c925bb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753570</td>\n",
       "      <td>4691.5</td>\n",
       "      <td>4635</td>\n",
       "      <td>onset</td>\n",
       "      <td>11.0</td>\n",
       "      <td>038441c925bb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.486544</td>\n",
       "      <td>4811.5</td>\n",
       "      <td>4755</td>\n",
       "      <td>onset</td>\n",
       "      <td>9.0</td>\n",
       "      <td>038441c925bb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.779183</td>\n",
       "      <td>4931.5</td>\n",
       "      <td>4875</td>\n",
       "      <td>onset</td>\n",
       "      <td>7.0</td>\n",
       "      <td>038441c925bb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.027495</td>\n",
       "      <td>4979.5</td>\n",
       "      <td>4923</td>\n",
       "      <td>onset</td>\n",
       "      <td>5.0</td>\n",
       "      <td>038441c925bb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  key_step  step  event  level     series_id\n",
       "0  0.039067    4331.5  4275  onset   13.0  038441c925bb\n",
       "1  0.753570    4691.5  4635  onset   11.0  038441c925bb\n",
       "2  2.486544    4811.5  4755  onset    9.0  038441c925bb\n",
       "3  5.779183    4931.5  4875  onset    7.0  038441c925bb\n",
       "4  7.027495    4979.5  4923  onset    5.0  038441c925bb"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(os.path.join(CFG[\"output_dir\"], \"submission.csv\"))\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(24.)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "score2range = scipy.interpolate.interp1d([-100, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 100], [0, 0, 12, 36, 60, 90, 120, 150, 180, 240, 300, 360, 360])\n",
    "range2score = scipy.interpolate.interp1d([0, 12, 36, 60, 90, 120, 150, 180, 240, 300, 360], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "score2range(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def process_group(df):\n",
    "    dfs = []\n",
    "    df = df.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "    used = np.zeros(len(df))\n",
    "    reduce_rate = np.ones(df[\"step\"].max() + 500)\n",
    "    for _ in range(len(df)):\n",
    "        best_score = -1e10\n",
    "        best_idx = -1\n",
    "        best_step = -1\n",
    "        best_row = -1\n",
    "        for i, row in df.iterrows():\n",
    "            if used[i]:\n",
    "                continue\n",
    "            score = row[\"score\"] / reduce_rate[row[\"step\"]]\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_idx = i\n",
    "                best_step = row[\"step\"]\n",
    "                row[\"reduced_score\"] = score\n",
    "                best_row = row\n",
    "        dfs.append(best_row)\n",
    "        used[best_idx] = True\n",
    "\n",
    "        range_ = score2range(best_score)\n",
    "        for r in range(1, int(range_)):\n",
    "            reduce = range2score(range_ - r) + 1\n",
    "            reduce_rate[best_step + r] = max(reduce_rate[best_step + r], reduce)\n",
    "            if best_step - r >= 0:\n",
    "                reduce_rate[best_step - r] = max(reduce_rate[best_step - r], reduce)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 269/269 [02:53<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "groups = [group for _, group in sub.groupby(\"series_id\")]\n",
    "with Pool(30) as p:\n",
    "    results = list(tqdm(p.imap(process_group, groups), total=len(groups)))\n",
    "all_results = [item for sublist in results for item in sublist]\n",
    "df = pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = df.copy()\n",
    "sub[\"score\"] = sub[\"reduced_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.7338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "event   tolerance\n",
       "onset   12           0.174365\n",
       "        36           0.560188\n",
       "        60           0.693139\n",
       "        90           0.765581\n",
       "        120          0.806428\n",
       "        150          0.821884\n",
       "        180          0.835242\n",
       "        240          0.849685\n",
       "        300          0.858759\n",
       "        360          0.866141\n",
       "wakeup  12           0.197140\n",
       "        36           0.574481\n",
       "        60           0.711930\n",
       "        90           0.785798\n",
       "        120          0.821630\n",
       "        150          0.842537\n",
       "        180          0.857021\n",
       "        240          0.872056\n",
       "        300          0.887292\n",
       "        360          0.895328\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# スコア計算\n",
    "labels = pd.read_csv(f\"{CFG['dataset']['competition_dir']}/train_events.csv\").dropna()\n",
    "score, ap_table = compute_comptetition_metric(labels, sub)\n",
    "print(f\"score: {score:.4f}\")\n",
    "display(ap_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
