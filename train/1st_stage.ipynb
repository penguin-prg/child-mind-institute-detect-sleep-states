{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-01 16:12:56.381531: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-01 16:12:56.557347: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-01 16:12:57.092216: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-10-01 16:12:57.092333: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-10-01 16:12:57.092338: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_050\n",
      "rm: cannot remove '/kaggle/output/exp_050': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('/kaggle/src')\n",
    "from utils.xgb import fit_xgb\n",
    "from utils.metric import compute_comptetition_metric\n",
    "from utils.postprocess import post_process\n",
    "from utils.set_seed import seed_base\n",
    "from feature_engineering.stage1 import generate_1st_stage_features\n",
    "\n",
    "PACKAGE_DIR = Path(\"/kaggle/src\")\n",
    "CFG = yaml.safe_load(open(PACKAGE_DIR / \"config.yaml\", \"r\"))\n",
    "print(CFG[\"1st_stage\"][\"execution\"][\"exp_id\"])\n",
    "\n",
    "CFG[\"output_dir\"] = f\"/kaggle/output/{CFG['1st_stage']['execution']['exp_id']}\"\n",
    "!rm -r {CFG[\"output_dir\"]}\n",
    "os.makedirs(CFG[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "seed_base(CFG[\"env\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generate features: 100%|██████████| 277/277 [07:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anglez_diff_abs</th>\n",
       "      <th>anglez_diff_abs_rolling_max_10</th>\n",
       "      <th>anglez_diff_abs_rolling_max_100</th>\n",
       "      <th>anglez_diff_abs_rolling_max_1000</th>\n",
       "      <th>anglez_diff_abs_rolling_max_50</th>\n",
       "      <th>anglez_diff_abs_rolling_mean_10</th>\n",
       "      <th>anglez_diff_abs_rolling_mean_100</th>\n",
       "      <th>anglez_diff_abs_rolling_mean_1000</th>\n",
       "      <th>anglez_diff_abs_rolling_mean_50</th>\n",
       "      <th>anglez_diff_abs_rolling_median_10</th>\n",
       "      <th>...</th>\n",
       "      <th>enmo_rolling_square_mean_50</th>\n",
       "      <th>enmo_rolling_std_10</th>\n",
       "      <th>enmo_rolling_std_100</th>\n",
       "      <th>enmo_rolling_std_1000</th>\n",
       "      <th>enmo_rolling_std_50</th>\n",
       "      <th>total_seconds</th>\n",
       "      <th>target</th>\n",
       "      <th>step</th>\n",
       "      <th>series_id</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006755</td>\n",
       "      <td>0.045741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40555.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051780</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40670.0</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>0.5969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400217</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.022484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020798</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>40785.0</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.348026</td>\n",
       "      <td>0.5969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.596900</td>\n",
       "      <td>0.082136</td>\n",
       "      <td>0.024780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041755</td>\n",
       "      <td>0.034920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>40900.0</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008796</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.5969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.405178</td>\n",
       "      <td>0.012594</td>\n",
       "      <td>0.028136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034873</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>41015.0</td>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   anglez_diff_abs  anglez_diff_abs_rolling_max_10  \\\n",
       "0         0.006755                        0.045741   \n",
       "1         0.000122                        0.000557   \n",
       "2         0.000726                        0.003443   \n",
       "3         0.085470                        0.348026   \n",
       "4         0.008796                        0.051000   \n",
       "\n",
       "   anglez_diff_abs_rolling_max_100  anglez_diff_abs_rolling_max_1000  \\\n",
       "0                              NaN                               NaN   \n",
       "1                              NaN                               NaN   \n",
       "2                           0.5969                               NaN   \n",
       "3                           0.5969                               NaN   \n",
       "4                           0.5969                               NaN   \n",
       "\n",
       "   anglez_diff_abs_rolling_max_50  anglez_diff_abs_rolling_mean_10  \\\n",
       "0                             NaN                         0.008228   \n",
       "1                        0.051780                         0.000113   \n",
       "2                        0.400217                         0.000802   \n",
       "3                        0.596900                         0.082136   \n",
       "4                        0.405178                         0.012594   \n",
       "\n",
       "   anglez_diff_abs_rolling_mean_100  anglez_diff_abs_rolling_mean_1000  \\\n",
       "0                               NaN                                NaN   \n",
       "1                               NaN                                NaN   \n",
       "2                          0.022484                                NaN   \n",
       "3                          0.024780                                NaN   \n",
       "4                          0.028136                                NaN   \n",
       "\n",
       "   anglez_diff_abs_rolling_mean_50  anglez_diff_abs_rolling_median_10  ...  \\\n",
       "0                              NaN                           0.000453  ...   \n",
       "1                         0.002316                           0.000000  ...   \n",
       "2                         0.020798                           0.000207  ...   \n",
       "3                         0.041755                           0.034920  ...   \n",
       "4                         0.034873                           0.004185  ...   \n",
       "\n",
       "   enmo_rolling_square_mean_50  enmo_rolling_std_10  enmo_rolling_std_100  \\\n",
       "0                          NaN             0.000000                   NaN   \n",
       "1                     0.000000             0.000000                   NaN   \n",
       "2                     0.000003             0.000000               0.00146   \n",
       "3                     0.000004             0.002008               0.00146   \n",
       "4                     0.000002             0.000000               0.00146   \n",
       "\n",
       "   enmo_rolling_std_1000  enmo_rolling_std_50  total_seconds  target   step  \\\n",
       "0                    NaN                  NaN        40555.0       1   11.0   \n",
       "1                    NaN             0.000000        40670.0       1   34.0   \n",
       "2                    NaN             0.001436        40785.0       1   57.0   \n",
       "3                    NaN             0.002064        40900.0       1   80.0   \n",
       "4                    NaN             0.000990        41015.0       1  103.0   \n",
       "\n",
       "      series_id  fold  \n",
       "0  af91d9a50547     3  \n",
       "1  af91d9a50547     3  \n",
       "2  af91d9a50547     3  \n",
       "3  af91d9a50547     3  \n",
       "4  af91d9a50547     3  \n",
       "\n",
       "[5 rows x 203 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5563016, 203)\n"
     ]
    }
   ],
   "source": [
    "# 特徴生成\n",
    "files = glob(f\"{CFG['dataset']['step_csv_dir']}/*.csv\")\n",
    "train, features = generate_1st_stage_features(files)\n",
    "\n",
    "# cv splitとマージ\n",
    "cv_split = pd.read_csv(CFG['dataset']['cv_split_path'])\n",
    "train[\"fold\"] = train[\"series_id\"].map(cv_split.set_index(\"series_id\")[\"fold\"])\n",
    "display(train.head(5))\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fold 0 ==\n",
      "[0]\teval-logloss:0.61247\n",
      "[100]\teval-logloss:0.09793\n",
      "[200]\teval-logloss:0.09833\n",
      "[229]\teval-logloss:0.09859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:35<02:20, 35.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fold 1 ==\n",
      "[0]\teval-logloss:0.61227\n",
      "[100]\teval-logloss:0.08199\n",
      "[200]\teval-logloss:0.08130\n",
      "[275]\teval-logloss:0.08200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:10<01:45, 35.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fold 2 ==\n",
      "[0]\teval-logloss:0.61256\n",
      "[100]\teval-logloss:0.08457\n",
      "[200]\teval-logloss:0.08431\n",
      "[243]\teval-logloss:0.08468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [01:41<01:06, 33.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fold 3 ==\n",
      "[0]\teval-logloss:0.61297\n",
      "[100]\teval-logloss:0.09306\n",
      "[200]\teval-logloss:0.09221\n",
      "[300]\teval-logloss:0.09275\n",
      "[313]\teval-logloss:0.09297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [02:16<00:34, 34.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fold 4 ==\n",
      "[0]\teval-logloss:0.61349\n",
      "[100]\teval-logloss:0.10523\n",
      "[200]\teval-logloss:0.10452\n",
      "[300]\teval-logloss:0.10395\n",
      "[400]\teval-logloss:0.10416\n",
      "[407]\teval-logloss:0.10432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:58<00:00, 35.65s/it]\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "trn_oof, models = fit_xgb(\n",
    "    X=train, \n",
    "    y=train[\"target\"], \n",
    "    folds=train[\"fold\"].astype(int), \n",
    "    features=features.all_features(),\n",
    "    params=CFG[\"1st_stage\"][\"xgboost\"], \n",
    "    es_rounds=100,\n",
    ")\n",
    "train[\"oof\"] = trn_oof\n",
    "train = train.drop(columns=features.all_features())\n",
    "train = train.sort_values([\"series_id\", \"step\"]).reset_index(drop=True)\n",
    "\n",
    "# 保存\n",
    "for i, model in enumerate(models):\n",
    "    model.save_model(os.path.join(CFG[\"output_dir\"], f'xgb_fold{i}.model'))\n",
    "with open(os.path.join(CFG[\"output_dir\"], \"features.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(features, f)\n",
    "train.to_csv(os.path.join(CFG[\"output_dir\"], \"oof.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "post process: 100%|██████████| 277/277 [00:49<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.5044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "event   tolerance\n",
       "onset   12           0.004411\n",
       "        36           0.046357\n",
       "        60           0.152982\n",
       "        90           0.350572\n",
       "        120          0.512056\n",
       "        150          0.612113\n",
       "        180          0.670808\n",
       "        240          0.727442\n",
       "        300          0.760642\n",
       "        360          0.775266\n",
       "wakeup  12           0.023016\n",
       "        36           0.176065\n",
       "        60           0.355648\n",
       "        90           0.506840\n",
       "        120          0.607997\n",
       "        150          0.672585\n",
       "        180          0.718312\n",
       "        240          0.778937\n",
       "        300          0.805807\n",
       "        360          0.829373\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 後処理\n",
    "sub = post_process(train)\n",
    "sub.to_csv(os.path.join(CFG[\"output_dir\"], \"submission.csv\"), index=False)\n",
    "\n",
    "# スコア計算\n",
    "labels = pd.read_csv(f\"{CFG['dataset']['competition_dir']}/train_events.csv\").dropna()\n",
    "score, ap_table = compute_comptetition_metric(labels, sub)\n",
    "print(f\"score: {score:.4f}\")\n",
    "display(ap_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.9722\n",
      "next_cand_size: 20842937.0\n"
     ]
    }
   ],
   "source": [
    "# 次の候補を決定\n",
    "next_cand_size = 0\n",
    "count = 0\n",
    "next_dict = {}\n",
    "for series_id, train_df in train.groupby(\"series_id\"):\n",
    "    train_df = train_df[(train_df[\"oof\"] >= 0.1) & (train_df[\"oof\"] <= 0.9)]\n",
    "    sub_df = sub[(sub[\"series_id\"] == series_id)]\n",
    "    label_df = labels[labels[\"series_id\"] == series_id]\n",
    "    pred_steps = train_df[\"step\"].values\n",
    "    sub_steps = sub_df[\"step\"].values\n",
    "    label_steps = label_df[\"step\"].values\n",
    "\n",
    "    if len(train_df) == 0:\n",
    "        continue\n",
    "    next_cand = np.zeros(int(max(max(pred_steps if len(pred_steps) > 0 else [0]), max(sub_steps if len(sub_steps) > 0 else [0]))) + CFG[\"feature\"][\"agg_freq\"])\n",
    "    for sub_step in sub_steps:\n",
    "        next_cand[int(sub_step - CFG[\"feature\"][\"agg_freq\"] * 10): int(sub_step + CFG[\"feature\"][\"agg_freq\"] * 10)] = 1\n",
    "    for pred_step in pred_steps:\n",
    "        next_cand[int(pred_step - CFG[\"feature\"][\"agg_freq\"] * 10): int(pred_step + CFG[\"feature\"][\"agg_freq\"] * 10)] = 1\n",
    "    next_cand_size += np.sum(next_cand)\n",
    "    next_dict[series_id] = np.where(next_cand)[0]\n",
    "\n",
    "    for label_step in label_steps:\n",
    "        if label_step < next_cand.shape[0]:\n",
    "            count += next_cand[int(label_step)]\n",
    "    \n",
    "recall = count / len(labels)\n",
    "print(f\"recall: {recall:.4f}\")\n",
    "print(f\"next_cand_size: {next_cand_size}\")\n",
    "\n",
    "with open(f\"{CFG['output_dir']}/next_cands.pkl\", \"wb\") as f:\n",
    "    pickle.dump(next_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
