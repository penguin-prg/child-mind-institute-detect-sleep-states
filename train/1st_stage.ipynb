{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 04:59:54.006130: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-12 04:59:54.075856: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-12 04:59:54.533894: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-10-12 04:59:54.533973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-10-12 04:59:54.533978: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug_nb1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('/kaggle/src')\n",
    "from utils.xgb import fit_xgb\n",
    "from utils.metric import compute_comptetition_metric\n",
    "from utils.postprocess import post_process\n",
    "from utils.set_seed import seed_base\n",
    "from feature_engineering.stage1 import generate_1st_stage_features\n",
    "\n",
    "PACKAGE_DIR = Path(\"/kaggle/src\")\n",
    "CFG = yaml.safe_load(open(PACKAGE_DIR / \"config.yaml\", \"r\"))\n",
    "print(CFG[\"1st_stage\"][\"execution\"][\"exp_id\"])\n",
    "\n",
    "CFG[\"output_dir\"] = f\"/kaggle/output/{CFG['1st_stage']['execution']['exp_id']}\"\n",
    "!rm -r {CFG[\"output_dir\"]}\n",
    "os.makedirs(CFG[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "seed_base(CFG[\"env\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generate features: 100%|██████████| 277/277 [04:57<00:00,  1.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anglez</th>\n",
       "      <th>anglez_amplit_360</th>\n",
       "      <th>anglez_amplit_360_min</th>\n",
       "      <th>anglez_amplit_60</th>\n",
       "      <th>anglez_amplit_60_min</th>\n",
       "      <th>anglez_amplit_720</th>\n",
       "      <th>anglez_amplit_720_min</th>\n",
       "      <th>anglez_diff_360_max</th>\n",
       "      <th>anglez_diff_360_mean</th>\n",
       "      <th>anglez_diff_60_max</th>\n",
       "      <th>...</th>\n",
       "      <th>enmo_min_720</th>\n",
       "      <th>enmo_var_360</th>\n",
       "      <th>enmo_var_60</th>\n",
       "      <th>enmo_var_720</th>\n",
       "      <th>hour</th>\n",
       "      <th>lids</th>\n",
       "      <th>target</th>\n",
       "      <th>step</th>\n",
       "      <th>series_id</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.790645</td>\n",
       "      <td>11.0</td>\n",
       "      <td>99.986168</td>\n",
       "      <td>1</td>\n",
       "      <td>11.5</td>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.783105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.813859</td>\n",
       "      <td>11.0</td>\n",
       "      <td>99.557610</td>\n",
       "      <td>1</td>\n",
       "      <td>35.5</td>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.684932</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>1.483303</td>\n",
       "      <td>11.0</td>\n",
       "      <td>99.026649</td>\n",
       "      <td>1</td>\n",
       "      <td>59.5</td>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.684932</td>\n",
       "      <td>7.538462</td>\n",
       "      <td>1.351724</td>\n",
       "      <td>11.0</td>\n",
       "      <td>98.592644</td>\n",
       "      <td>1</td>\n",
       "      <td>83.5</td>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.013699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.351724</td>\n",
       "      <td>11.0</td>\n",
       "      <td>98.226341</td>\n",
       "      <td>1</td>\n",
       "      <td>107.5</td>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   anglez  anglez_amplit_360  anglez_amplit_360_min  anglez_amplit_60  \\\n",
       "0    88.0                0.0                    0.0               0.0   \n",
       "1    88.0                0.0                    0.0               0.0   \n",
       "2    88.0                0.0                    0.0               0.0   \n",
       "3    88.0                0.0                    0.0               0.0   \n",
       "4    88.0                0.0                    0.0               0.0   \n",
       "\n",
       "   anglez_amplit_60_min  anglez_amplit_720  anglez_amplit_720_min  \\\n",
       "0                   0.0                0.0                    0.0   \n",
       "1                   0.0                0.0                    0.0   \n",
       "2                   0.0                0.0                    0.0   \n",
       "3                   0.0                0.0                    0.0   \n",
       "4                   0.0                0.0                    0.0   \n",
       "\n",
       "   anglez_diff_360_max  anglez_diff_360_mean  anglez_diff_60_max  ...  \\\n",
       "0                  0.0                   0.0                 0.0  ...   \n",
       "1                  0.0                   0.0                 0.0  ...   \n",
       "2                  0.0                   0.0                 0.0  ...   \n",
       "3                  0.0                   0.0                 0.0  ...   \n",
       "4                  0.0                   0.0                 0.0  ...   \n",
       "\n",
       "   enmo_min_720  enmo_var_360  enmo_var_60  enmo_var_720  hour       lids  \\\n",
       "0           0.0      0.000000     0.000000      1.790645  11.0  99.986168   \n",
       "1           0.0      0.783105     0.000000      1.813859  11.0  99.557610   \n",
       "2           0.0      2.684932     0.628205      1.483303  11.0  99.026649   \n",
       "3           0.0      2.684932     7.538462      1.351724  11.0  98.592644   \n",
       "4           0.0      2.013699     0.000000      1.351724  11.0  98.226341   \n",
       "\n",
       "   target   step     series_id  fold  \n",
       "0       1   11.5  af91d9a50547     3  \n",
       "1       1   35.5  af91d9a50547     3  \n",
       "2       1   59.5  af91d9a50547     3  \n",
       "3       1   83.5  af91d9a50547     3  \n",
       "4       1  107.5  af91d9a50547     3  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5331163, 93)\n"
     ]
    }
   ],
   "source": [
    "# 特徴生成\n",
    "files = glob(f\"{CFG['dataset']['step_csv_dir']}/*.csv\")\n",
    "train, features = generate_1st_stage_features(files)\n",
    "\n",
    "# cv splitとマージ\n",
    "cv_split = pd.read_csv(CFG['dataset']['cv_split_path'])\n",
    "train[\"fold\"] = train[\"series_id\"].map(cv_split.set_index(\"series_id\")[\"fold\"])\n",
    "display(train.head(5))\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fold 0 ==\n",
      "[0]\teval-logloss:0.61800\n",
      "[100]\teval-logloss:0.14359\n",
      "[200]\teval-logloss:0.14106\n",
      "[300]\teval-logloss:0.14036\n",
      "[400]\teval-logloss:0.14036\n",
      "[478]\teval-logloss:0.14073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:11<00:47, 11.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fold 1 ==\n",
      "[0]\teval-logloss:0.61854\n",
      "[100]\teval-logloss:0.13594\n",
      "[200]\teval-logloss:0.13179\n",
      "[300]\teval-logloss:0.13072\n",
      "[400]\teval-logloss:0.13082\n",
      "[449]\teval-logloss:0.13091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:22<00:33, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fold 2 ==\n",
      "[0]\teval-logloss:0.61694\n",
      "[100]\teval-logloss:0.11889\n",
      "[200]\teval-logloss:0.11457\n",
      "[300]\teval-logloss:0.11296\n",
      "[400]\teval-logloss:0.11212\n",
      "[500]\teval-logloss:0.11174\n",
      "[600]\teval-logloss:0.11151\n",
      "[700]\teval-logloss:0.11130\n",
      "[800]\teval-logloss:0.11108\n",
      "[900]\teval-logloss:0.11116\n",
      "[905]\teval-logloss:0.11117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:40<00:28, 14.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fold 3 ==\n",
      "[0]\teval-logloss:0.61831\n",
      "[100]\teval-logloss:0.15238\n",
      "[200]\teval-logloss:0.14930\n",
      "[300]\teval-logloss:0.14873\n",
      "[400]\teval-logloss:0.14903\n",
      "[405]\teval-logloss:0.14902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:50<00:12, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fold 4 ==\n",
      "[0]\teval-logloss:0.61722\n",
      "[100]\teval-logloss:0.13821\n",
      "[200]\teval-logloss:0.13493\n",
      "[300]\teval-logloss:0.13397\n",
      "[400]\teval-logloss:0.13340\n",
      "[500]\teval-logloss:0.13302\n",
      "[600]\teval-logloss:0.13289\n",
      "[700]\teval-logloss:0.13276\n",
      "[800]\teval-logloss:0.13276\n",
      "[880]\teval-logloss:0.13276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:07<00:00, 13.50s/it]\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "trn_oof, models = fit_xgb(\n",
    "    X=train, \n",
    "    y=train[\"target\"], \n",
    "    folds=train[\"fold\"].astype(int), \n",
    "    features=features.all_features(),\n",
    "    params=CFG[\"1st_stage\"][\"xgboost\"], \n",
    "    es_rounds=100,\n",
    ")\n",
    "train[\"oof\"] = trn_oof\n",
    "train = train.drop(columns=features.all_features())\n",
    "train = train.sort_values([\"series_id\", \"step\"]).reset_index(drop=True)\n",
    "\n",
    "# 保存\n",
    "for i, model in enumerate(models):\n",
    "    model.save_model(os.path.join(CFG[\"output_dir\"], f'xgb_fold{i}.model'))\n",
    "with open(os.path.join(CFG[\"output_dir\"], \"features.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(features, f)\n",
    "train.to_csv(os.path.join(CFG[\"output_dir\"], \"oof.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "post process: 100%|██████████| 277/277 [00:47<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.5134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "event   tolerance\n",
       "onset   12           0.008740\n",
       "        36           0.088411\n",
       "        60           0.234192\n",
       "        90           0.401707\n",
       "        120          0.550090\n",
       "        150          0.614920\n",
       "        180          0.666100\n",
       "        240          0.717581\n",
       "        300          0.746268\n",
       "        360          0.764013\n",
       "wakeup  12           0.030577\n",
       "        36           0.211169\n",
       "        60           0.387835\n",
       "        90           0.542944\n",
       "        120          0.617508\n",
       "        150          0.670464\n",
       "        180          0.702971\n",
       "        240          0.747589\n",
       "        300          0.771596\n",
       "        360          0.792500\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 後処理\n",
    "sub = post_process(train)\n",
    "sub.to_csv(os.path.join(CFG[\"output_dir\"], \"submission.csv\"), index=False)\n",
    "\n",
    "# スコア計算\n",
    "labels = pd.read_csv(f\"{CFG['dataset']['competition_dir']}/train_events.csv\").dropna()\n",
    "score, ap_table = compute_comptetition_metric(labels, sub)\n",
    "print(f\"score: {score:.4f}\")\n",
    "display(ap_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.9864\n",
      "next_cand_size: 42295068.0\n"
     ]
    }
   ],
   "source": [
    "# 次の候補を決定\n",
    "next_cand_size = 0\n",
    "count = 0\n",
    "next_dict = {}\n",
    "for series_id, train_df in train.groupby(\"series_id\"):\n",
    "    train_df = train_df[(train_df[\"oof\"] >= 0.1) & (train_df[\"oof\"] <= 0.9)]\n",
    "    sub_df = sub[(sub[\"series_id\"] == series_id)]\n",
    "    label_df = labels[labels[\"series_id\"] == series_id]\n",
    "    pred_steps = train_df[\"step\"].values\n",
    "    sub_steps = sub_df[\"step\"].values\n",
    "    label_steps = label_df[\"step\"].values\n",
    "\n",
    "    if len(train_df) == 0:\n",
    "        continue\n",
    "    next_cand = np.zeros(int(max(max(pred_steps if len(pred_steps) > 0 else [0]), max(sub_steps if len(sub_steps) > 0 else [0]))) + CFG[\"feature\"][\"agg_freq\"])\n",
    "    for sub_step in sub_steps:\n",
    "        next_cand[int(sub_step - CFG[\"feature\"][\"agg_freq\"] * 10): int(sub_step + CFG[\"feature\"][\"agg_freq\"] * 10)] = 1\n",
    "    for pred_step in pred_steps:\n",
    "        next_cand[int(pred_step - CFG[\"feature\"][\"agg_freq\"] * 10): int(pred_step + CFG[\"feature\"][\"agg_freq\"] * 10)] = 1\n",
    "    next_cand_size += np.sum(next_cand)\n",
    "    next_dict[series_id] = np.where(next_cand)[0]\n",
    "\n",
    "    for label_step in label_steps:\n",
    "        if label_step < next_cand.shape[0]:\n",
    "            count += next_cand[int(label_step)]\n",
    "    \n",
    "recall = count / len(labels)\n",
    "print(f\"recall: {recall:.4f}\")\n",
    "print(f\"next_cand_size: {next_cand_size}\")\n",
    "\n",
    "with open(f\"{CFG['output_dir']}/next_cands.pkl\", \"wb\") as f:\n",
    "    pickle.dump(next_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
