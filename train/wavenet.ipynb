{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-05 10:33:18.328104: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-10-05 10:33:18.328453: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-10-05 10:33:18.328459: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_070\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import MetricCollection, MeanSquaredError\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('/kaggle/src')\n",
    "from utils.set_seed import seed_base_torch\n",
    "from utils.feature_contena import Features\n",
    "from utils.lightning_utils import MyLightningDataModule\n",
    "\n",
    "PACKAGE_DIR = Path(\"/kaggle/src\")\n",
    "CFG = yaml.safe_load(open(PACKAGE_DIR / \"config.yaml\", \"r\"))\n",
    "print(CFG[\"wavenet\"][\"execution\"][\"exp_id\"])\n",
    "\n",
    "CFG[\"output_dir\"] = f\"/kaggle/output/{CFG['wavenet']['execution']['exp_id']}\"\n",
    "!rm -r {CFG[\"output_dir\"]}\n",
    "os.makedirs(CFG[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "seed_base_torch(CFG[\"env\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 150\n",
    "NNBATCHSIZE = 64\n",
    "GROUP_BATCH_SIZE = 4000\n",
    "SEED = 321\n",
    "LR = 0.001\n",
    "SPLITS = 5\n",
    "\n",
    "ENMO_MEAN = 0.041315\n",
    "ANGLEZ_MEAN = -8.810453\n",
    "ENMO_STD = 0.101829\n",
    "ANGLEZ_STD = 35.521877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(train: pd.DataFrame):\n",
    "    features = Features()\n",
    "    features.add_num_features([\"anglez\", \"enmo\"])\n",
    "\n",
    "    # 時刻\n",
    "    timestamp = pd.to_datetime(train[\"timestamp\"].values[0])\n",
    "    total_seconds = (timestamp - timestamp.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds()\n",
    "    train[\"total_seconds\"] = (total_seconds + train.index * 5) % (24 * 60 * 60) # [sec]\n",
    "    train[\"total_seconds\"] /= train[\"total_seconds\"].max() - 0.5\n",
    "    features.add_num_feature(\"total_seconds\")    \n",
    "\n",
    "    columns = [\"anglez\", \"enmo\"]\n",
    "\n",
    "    # その人のその時刻での平均的な測定値\n",
    "    gb = train.groupby(\"total_seconds\")[columns].mean()\n",
    "    gb.columns = [f\"{c}_mean\" for c in columns]\n",
    "    train[\"anglez_mean\"] = train[\"total_seconds\"].map(gb[\"anglez_mean\"])\n",
    "    train[\"enmo_mean\"] = train[\"total_seconds\"].map(gb[\"enmo_mean\"])\n",
    "    features.add_num_features(gb.columns.tolist())\n",
    "    columns += gb.columns.tolist()\n",
    "\n",
    "    # diff\n",
    "    for c in features.all_features():\n",
    "        for t in [-1, 1]:\n",
    "            train[f\"{c}_diff_{t}\"] = (train[c] - train[c].shift(t)).fillna(0)\n",
    "            features.add_num_feature(f\"{c}_diff_{t}\")\n",
    "    return train, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:23<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64107\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>anglez</th>\n",
       "      <th>enmo</th>\n",
       "      <th>event</th>\n",
       "      <th>target</th>\n",
       "      <th>total_seconds</th>\n",
       "      <th>anglez_mean</th>\n",
       "      <th>enmo_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>anglez_diff_1</th>\n",
       "      <th>anglez_mean_diff_-1</th>\n",
       "      <th>anglez_mean_diff_1</th>\n",
       "      <th>enmo_diff_-1</th>\n",
       "      <th>enmo_diff_1</th>\n",
       "      <th>enmo_mean_diff_-1</th>\n",
       "      <th>enmo_mean_diff_1</th>\n",
       "      <th>total_seconds_diff_-1</th>\n",
       "      <th>total_seconds_diff_1</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-05T11:15:00-0500</td>\n",
       "      <td>2.747173</td>\n",
       "      <td>-0.405729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.468780</td>\n",
       "      <td>-0.337581</td>\n",
       "      <td>0.476960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-05T11:15:05-0500</td>\n",
       "      <td>2.747199</td>\n",
       "      <td>-0.405729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.468838</td>\n",
       "      <td>-0.336448</td>\n",
       "      <td>0.395982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.039054</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.062687</td>\n",
       "      <td>-0.080977</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-05T11:15:10-0500</td>\n",
       "      <td>2.747283</td>\n",
       "      <td>-0.405729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.468896</td>\n",
       "      <td>-0.375502</td>\n",
       "      <td>0.458669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>-0.064311</td>\n",
       "      <td>-0.039054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.039977</td>\n",
       "      <td>0.062687</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-02-05T11:15:15-0500</td>\n",
       "      <td>2.747182</td>\n",
       "      <td>-0.405729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.468953</td>\n",
       "      <td>-0.311192</td>\n",
       "      <td>0.498646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>0.039922</td>\n",
       "      <td>0.064311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.114448</td>\n",
       "      <td>0.039977</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-02-05T11:15:20-0500</td>\n",
       "      <td>2.747308</td>\n",
       "      <td>-0.405729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.469011</td>\n",
       "      <td>-0.351114</td>\n",
       "      <td>0.613095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.053927</td>\n",
       "      <td>-0.039922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163387</td>\n",
       "      <td>0.114448</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3995</td>\n",
       "      <td>2018-02-05T16:47:55-0500</td>\n",
       "      <td>-1.019410</td>\n",
       "      <td>-0.152363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.699987</td>\n",
       "      <td>-0.203260</td>\n",
       "      <td>0.601801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224729</td>\n",
       "      <td>0.146731</td>\n",
       "      <td>0.118163</td>\n",
       "      <td>-0.122755</td>\n",
       "      <td>-0.118827</td>\n",
       "      <td>0.133394</td>\n",
       "      <td>0.039732</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3996</td>\n",
       "      <td>2018-02-05T16:48:00-0500</td>\n",
       "      <td>-1.153043</td>\n",
       "      <td>-0.029608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700045</td>\n",
       "      <td>-0.349991</td>\n",
       "      <td>0.468408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133633</td>\n",
       "      <td>0.086902</td>\n",
       "      <td>-0.146731</td>\n",
       "      <td>0.164982</td>\n",
       "      <td>0.122755</td>\n",
       "      <td>-0.032776</td>\n",
       "      <td>-0.133394</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3997</td>\n",
       "      <td>2018-02-05T16:48:05-0500</td>\n",
       "      <td>-0.906871</td>\n",
       "      <td>-0.194591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700102</td>\n",
       "      <td>-0.436893</td>\n",
       "      <td>0.501183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246172</td>\n",
       "      <td>0.084591</td>\n",
       "      <td>-0.086902</td>\n",
       "      <td>0.055976</td>\n",
       "      <td>-0.164982</td>\n",
       "      <td>0.159213</td>\n",
       "      <td>0.032776</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3998</td>\n",
       "      <td>2018-02-05T16:48:10-0500</td>\n",
       "      <td>-0.871929</td>\n",
       "      <td>-0.250567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700160</td>\n",
       "      <td>-0.521484</td>\n",
       "      <td>0.341970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034942</td>\n",
       "      <td>-0.071669</td>\n",
       "      <td>-0.084591</td>\n",
       "      <td>-0.054012</td>\n",
       "      <td>-0.055976</td>\n",
       "      <td>-0.597570</td>\n",
       "      <td>-0.159213</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3999</td>\n",
       "      <td>2018-02-05T16:48:15-0500</td>\n",
       "      <td>-0.921470</td>\n",
       "      <td>-0.196555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700218</td>\n",
       "      <td>-0.449816</td>\n",
       "      <td>0.939541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049541</td>\n",
       "      <td>-0.124180</td>\n",
       "      <td>0.071669</td>\n",
       "      <td>-0.228815</td>\n",
       "      <td>0.054012</td>\n",
       "      <td>0.632269</td>\n",
       "      <td>0.597570</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         series_id  step                 timestamp    anglez      enmo event  \\\n",
       "0     af91d9a50547     0  2018-02-05T11:15:00-0500  2.747173 -0.405729   NaN   \n",
       "1     af91d9a50547     1  2018-02-05T11:15:05-0500  2.747199 -0.405729   NaN   \n",
       "2     af91d9a50547     2  2018-02-05T11:15:10-0500  2.747283 -0.405729   NaN   \n",
       "3     af91d9a50547     3  2018-02-05T11:15:15-0500  2.747182 -0.405729   NaN   \n",
       "4     af91d9a50547     4  2018-02-05T11:15:20-0500  2.747308 -0.405729   NaN   \n",
       "...            ...   ...                       ...       ...       ...   ...   \n",
       "3995  af91d9a50547  3995  2018-02-05T16:47:55-0500 -1.019410 -0.152363   NaN   \n",
       "3996  af91d9a50547  3996  2018-02-05T16:48:00-0500 -1.153043 -0.029608   NaN   \n",
       "3997  af91d9a50547  3997  2018-02-05T16:48:05-0500 -0.906871 -0.194591   NaN   \n",
       "3998  af91d9a50547  3998  2018-02-05T16:48:10-0500 -0.871929 -0.250567   NaN   \n",
       "3999  af91d9a50547  3999  2018-02-05T16:48:15-0500 -0.921470 -0.196555   NaN   \n",
       "\n",
       "      target  total_seconds  anglez_mean  enmo_mean  ...  anglez_diff_1  \\\n",
       "0          1       0.468780    -0.337581   0.476960  ...       0.000000   \n",
       "1          1       0.468838    -0.336448   0.395982  ...       0.000025   \n",
       "2          1       0.468896    -0.375502   0.458669  ...       0.000084   \n",
       "3          1       0.468953    -0.311192   0.498646  ...      -0.000101   \n",
       "4          1       0.469011    -0.351114   0.613095  ...       0.000127   \n",
       "...      ...            ...          ...        ...  ...            ...   \n",
       "3995       1       0.699987    -0.203260   0.601801  ...       0.224729   \n",
       "3996       1       0.700045    -0.349991   0.468408  ...      -0.133633   \n",
       "3997       1       0.700102    -0.436893   0.501183  ...       0.246172   \n",
       "3998       1       0.700160    -0.521484   0.341970  ...       0.034942   \n",
       "3999       1       0.700218    -0.449816   0.939541  ...      -0.049541   \n",
       "\n",
       "      anglez_mean_diff_-1  anglez_mean_diff_1  enmo_diff_-1  enmo_diff_1  \\\n",
       "0               -0.001133            0.000000      0.000000     0.000000   \n",
       "1                0.039054            0.001133      0.000000     0.000000   \n",
       "2               -0.064311           -0.039054      0.000000     0.000000   \n",
       "3                0.039922            0.064311      0.000000     0.000000   \n",
       "4                0.053927           -0.039922      0.000000     0.000000   \n",
       "...                   ...                 ...           ...          ...   \n",
       "3995             0.146731            0.118163     -0.122755    -0.118827   \n",
       "3996             0.086902           -0.146731      0.164982     0.122755   \n",
       "3997             0.084591           -0.086902      0.055976    -0.164982   \n",
       "3998            -0.071669           -0.084591     -0.054012    -0.055976   \n",
       "3999            -0.124180            0.071669     -0.228815     0.054012   \n",
       "\n",
       "      enmo_mean_diff_-1  enmo_mean_diff_1  total_seconds_diff_-1  \\\n",
       "0              0.080977          0.000000              -0.000058   \n",
       "1             -0.062687         -0.080977              -0.000058   \n",
       "2             -0.039977          0.062687              -0.000058   \n",
       "3             -0.114448          0.039977              -0.000058   \n",
       "4              0.163387          0.114448              -0.000058   \n",
       "...                 ...               ...                    ...   \n",
       "3995           0.133394          0.039732              -0.000058   \n",
       "3996          -0.032776         -0.133394              -0.000058   \n",
       "3997           0.159213          0.032776              -0.000058   \n",
       "3998          -0.597570         -0.159213              -0.000058   \n",
       "3999           0.632269          0.597570              -0.000058   \n",
       "\n",
       "      total_seconds_diff_1  fold  \n",
       "0                 0.000000     3  \n",
       "1                 0.000058     3  \n",
       "2                 0.000058     3  \n",
       "3                 0.000058     3  \n",
       "4                 0.000058     3  \n",
       "...                    ...   ...  \n",
       "3995              0.000058     3  \n",
       "3996              0.000058     3  \n",
       "3997              0.000058     3  \n",
       "3998              0.000058     3  \n",
       "3999              0.000058     3  \n",
       "\n",
       "[4000 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(f\"{CFG['dataset']['step_csv_dir']}/*.csv\")\n",
    "cv_split = pd.read_csv(CFG['dataset']['cv_split_path'])\n",
    "dfs = []\n",
    "for f in tqdm(files):\n",
    "    df = pd.read_csv(f)\n",
    "\n",
    "    # normalize\n",
    "    df[\"enmo\"] = (df[\"enmo\"] - ENMO_MEAN) / ENMO_STD\n",
    "    df[\"anglez\"] = (df[\"anglez\"] - ANGLEZ_MEAN) / ANGLEZ_STD\n",
    "\n",
    "    # feature engineering\n",
    "    train, features = generate_features(df)\n",
    "\n",
    "    sid = df[\"series_id\"].values[0]\n",
    "    df[\"fold\"] = cv_split.loc[cv_split[\"series_id\"] == sid, \"fold\"].values[0]\n",
    "    for start in range(0, len(df), GROUP_BATCH_SIZE // 2):\n",
    "        end = start + GROUP_BATCH_SIZE\n",
    "        if end > len(df):\n",
    "            end = len(df)\n",
    "            start = end - GROUP_BATCH_SIZE\n",
    "            assert start >= 0\n",
    "        dfs.append(df.iloc[start: end])\n",
    "gc.collect()\n",
    "print(len(dfs))\n",
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZzzDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dfs: list[pd.DataFrame], mode: str, features: Features):\n",
    "        self.dfs = dfs\n",
    "        self.mode = mode\n",
    "        self.features = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dfs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        df = self.dfs[index]\n",
    "\n",
    "        feats = df[self.features.all_features()].values.astype(np.float32)\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            targets = df[\"target\"].values.astype(np.float32)\n",
    "            return feats, targets\n",
    "        else:\n",
    "            return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.torch_models import WaveBlock    \n",
    "from utils.lightning_utils import MyLightningDataModule\n",
    "    \n",
    "class WaveNetModel(pl.LightningModule):\n",
    "    def __init__(self, dim_input: int, loss_fn=nn.CrossEntropyLoss(), lr=0.001, weight_decay=0):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay    \n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "        input_size = 128\n",
    "        self.LSTM1 = nn.GRU(input_size=dim_input, hidden_size=64, num_layers=2, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.LSTM = nn.GRU(input_size=input_size, hidden_size=64, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        #self.attention = Attention(input_size,4000)\n",
    "        #self.rnn = nn.RNN(input_size, 64, 2, batch_first=True, nonlinearity='relu')\n",
    "               \n",
    "        self.wave_block1 = WaveBlock(128, 16, 4)\n",
    "        self.wave_block2 = WaveBlock(16, 32, 4)\n",
    "        self.wave_block3 = WaveBlock(32, 64, 2)\n",
    "        self.wave_block4 = WaveBlock(64, 128, 1)\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "        \n",
    "        self.train_metrics = MetricCollection([], prefix=\"\")\n",
    "        self.valid_metrics = MetricCollection([], prefix=\"val_\")\n",
    "        \n",
    "        self.val_step_outputs = []\n",
    "        self.val_step_labels = []\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        slen = x.shape[1]\n",
    "\n",
    "        x,_ = self.LSTM1(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "      \n",
    "        x = self.wave_block1(x)\n",
    "        x = self.wave_block2(x)\n",
    "        x = self.wave_block3(x)\n",
    "        \n",
    "        #x,_ = self.LSTM(x)\n",
    "        x = self.wave_block4(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x,_ = self.LSTM(x)\n",
    "        #x = self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        #x = self.rnn(x)\n",
    "        #x = self.attention(x)\n",
    "        x = self.fc(x)\n",
    "        logits = x.view(bs, slen)\n",
    "        return logits\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=3, verbose=True)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "    \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        preds = self.forward(X)\n",
    "\n",
    "        loss = self.loss_fn(preds, y)\n",
    "\n",
    "        self.train_metrics(preds, y)\n",
    "        self.log(\n",
    "            \"loss\",\n",
    "            loss,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        self.log_dict(\n",
    "            self.train_metrics,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "            on_epoch=True,\n",
    "            on_step=True,\n",
    "        )\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        preds = self.forward(X)\n",
    "\n",
    "        self.val_step_outputs.append(preds)\n",
    "        self.val_step_labels.append(y)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        preds = torch.cat(self.val_step_outputs)\n",
    "        labels = torch.cat(self.val_step_labels)\n",
    "        self.val_step_outputs.clear()\n",
    "        self.val_step_labels.clear()\n",
    "        loss = self.loss_fn(preds, labels)\n",
    "\n",
    "        self.valid_metrics(preds, labels)\n",
    "        self.log(\n",
    "            \"val_loss\",\n",
    "            loss,\n",
    "            prog_bar=False,\n",
    "            logger=True,\n",
    "            on_epoch=True,\n",
    "            on_step=False,\n",
    "        )\n",
    "        self.log_dict(\n",
    "            self.valid_metrics,\n",
    "            prog_bar=False,\n",
    "            logger=True,\n",
    "            on_epoch=True,\n",
    "            on_step=False,\n",
    "        )\n",
    "\n",
    "        # ログをprint\n",
    "        self.print_metric(preds, labels, \"valid\")\n",
    "\n",
    "    def print_metric(self, y_hat, y, train_or_valid=\"train\"):\n",
    "        \"\"\"\n",
    "        ログをprintする。次のepochが終わると上書きされてしまうので。\n",
    "        TODO: たぶんもっとマシな方法があるので探す。\n",
    "        \"\"\"\n",
    "        if train_or_valid == \"train\":\n",
    "            metrics = self.train_metrics\n",
    "        else:\n",
    "            metrics = self.valid_metrics\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "\n",
    "        print(f\"[epoch {self.trainer.current_epoch}] {train_or_valid}: \", end=\"\")\n",
    "        print(f\"{type(self.loss_fn).__name__}={loss:.4f}\", end=\", \")\n",
    "        for name in metrics:\n",
    "            v = metrics[name](y_hat, y)\n",
    "            print(f\"{name}={v:.4f}\", end=\", \")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Features()\n",
    "features.add_num_features([\"anglez\", \"enmo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'logs': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fold 0 ==\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee9dff920104c20b3fd6fcab556266e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] valid: BCEWithLogitsLoss=0.6766, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522ba0bae2d14e58b03ece991208178c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68683b940e7f41ada1ca3d45c67bf74f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] valid: BCEWithLogitsLoss=0.1569, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9ecdb8030a4b13b4fed92ae0328f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] valid: BCEWithLogitsLoss=0.1151, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5dbfa7deed48ca96cb8e9f83d468c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] valid: BCEWithLogitsLoss=0.1183, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d5e34c55c54aa986176fed649f985c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] valid: BCEWithLogitsLoss=0.1111, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318fe90383ee45569b73e2984cbef866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] valid: BCEWithLogitsLoss=0.1110, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c18389c99cf4ec3b704e81a02758c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] valid: BCEWithLogitsLoss=0.1106, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216349498d7548c3871fa771bf472cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] valid: BCEWithLogitsLoss=0.1142, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8662283dd7b84dbba432fcf88eac3bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] valid: BCEWithLogitsLoss=0.1248, \n"
     ]
    }
   ],
   "source": [
    "fold_oof_dfs = []\n",
    "for fold in range(5):\n",
    "    print(f\"== fold {fold} ==\")\n",
    "    \n",
    "    # 学習・評価データ\n",
    "    train_dfs = [df for df in dfs if df[\"fold\"].unique()[0] != fold]\n",
    "    valid_dfs = [df for df in dfs if df[\"fold\"].unique()[0] == fold]\n",
    "    train_dataset = ZzzDataset(train_dfs, mode=\"train\", features=features)\n",
    "    valid_dataset = ZzzDataset(valid_dfs, mode=\"train\", features=features)\n",
    "    data_module = MyLightningDataModule(train_dataset, valid_dataset, batch_size=NNBATCHSIZE)\n",
    "\n",
    "    # モデル\n",
    "    model = WaveNetModel(lr=LR, dim_input=len(features.all_features()), loss_fn=nn.BCEWithLogitsLoss())\n",
    "    \n",
    "    # コールバック\n",
    "    cp_callback = ModelCheckpoint(\n",
    "        \"logs/\", \n",
    "        filename=f\"best_model_fold{fold}\",\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=1,\n",
    "        save_last=False,\n",
    "    )\n",
    "    es_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        patience=5,\n",
    "    )\n",
    "\n",
    "    # 学習\n",
    "    trainer = pl.Trainer(\n",
    "        callbacks=[cp_callback, es_callback],\n",
    "        )\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "    # 推論\n",
    "    preds = []\n",
    "    model = WaveNetModel.load_from_checkpoint(f\"logs/best_model_fold{fold}.ckpt\", dim_impput=len(features.all_features()), lr=0.001, loss_fn=nn.BCEWithLogitsLoss()).to(\"cuda\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_module.val_dataloader():\n",
    "            pred = F.sigmoid(model(X.to(\"cuda\"))).detach().cpu().numpy()\n",
    "            preds.append(pred)\n",
    "\n",
    "    oof_dfs = []\n",
    "    for pred, df in zip(np.vstack(preds), valid_dfs):\n",
    "        df[\"oof\"] = pred\n",
    "        df = df.drop(columns=features.all_features())\n",
    "        oof_dfs.append(df)\n",
    "\n",
    "    oof_df = pd.concat(oof_dfs)\n",
    "    oof_df = oof_df.groupby([\"series_id\", \"step\"]).mean().reset_index().sort_values([\"series_id\", \"step\"])\n",
    "    fold_oof_dfs.append(oof_df)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
