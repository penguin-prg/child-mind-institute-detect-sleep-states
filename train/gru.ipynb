{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 01:32:45.319936: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-10-14 01:32:45.320184: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-10-14 01:32:45.320190: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_081\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "from glob import glob\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import MetricCollection, MeanSquaredError\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "sys.path.append('/kaggle/src')\n",
    "from utils.metric import compute_comptetition_metric\n",
    "from utils.postprocess import post_process\n",
    "from utils.set_seed import seed_base_torch\n",
    "from utils.feature_contena import Features\n",
    "from utils.lightning_utils import MyLightningDataModule\n",
    "\n",
    "PACKAGE_DIR = Path(\"/kaggle/src\")\n",
    "CFG = yaml.safe_load(open(PACKAGE_DIR / \"config.yaml\", \"r\"))\n",
    "print(CFG[\"gru\"][\"execution\"][\"exp_id\"])\n",
    "\n",
    "CFG[\"output_dir\"] = f\"/kaggle/output/{CFG['gru']['execution']['exp_id']}\"\n",
    "!rm -r {CFG[\"output_dir\"]}\n",
    "os.makedirs(CFG[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "seed_base_torch(CFG[\"env\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANGLEZ_MEAN = -8.810\n",
    "ANGLEZ_STD = 35.52\n",
    "ENMO_MEAN = 0.04132\n",
    "ENMO_STD = 0.1018\n",
    "\n",
    "SEQ_LEN = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZzzDataset(Dataset):\n",
    "    def __init__(self, dfs: list[pd.DataFrame], mode: str, features: Features):\n",
    "        self.dfs = dfs\n",
    "        self.mode = mode\n",
    "        self.features = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dfs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        df = self.dfs[index]\n",
    "\n",
    "        feats = df[self.features.all_features()].values.astype(np.float32)\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            targets = df[[\"wakeup_target\", \"onset_target\"]].values.astype(np.float32)\n",
    "            return feats, targets\n",
    "        else:\n",
    "            return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZzzGRUModule(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self, \n",
    "            dropout=0.2,\n",
    "            input_numerical_size=2,\n",
    "            numeraical_linear_size = 64,\n",
    "            model_size = 128,\n",
    "            linear_out = 128,\n",
    "            out_size=2,\n",
    "            loss_fn=nn.CrossEntropyLoss(), \n",
    "            lr=0.001, \n",
    "            weight_decay=0\n",
    "        ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.numerical_linear  = nn.Sequential(\n",
    "                nn.Linear(input_numerical_size, numeraical_linear_size),\n",
    "                nn.LayerNorm(numeraical_linear_size)\n",
    "            )\n",
    "        \n",
    "        self.rnn = nn.GRU(numeraical_linear_size, model_size,\n",
    "                            num_layers = 2, \n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.linear_out  = nn.Sequential(\n",
    "            nn.Linear(model_size*2, linear_out),\n",
    "            nn.LayerNorm(linear_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(linear_out, out_size))\n",
    "        self._reinitialize()\n",
    "\n",
    "        self.loss_fn = loss_fn\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        self.train_metrics = MetricCollection([], prefix=\"\")\n",
    "        self.valid_metrics = MetricCollection([], prefix=\"val_\")\n",
    "        \n",
    "        self.val_step_outputs = []\n",
    "        self.val_step_labels = []\n",
    "\n",
    "\n",
    "    def _reinitialize(self):\n",
    "        \"\"\"\n",
    "        Tensorflow/Keras-like initialization\n",
    "        \"\"\"\n",
    "        for name, p in self.named_parameters():\n",
    "            if 'rnn' in name:\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(p.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    p.data.fill_(0)\n",
    "                    # Set forget-gate bias to 1\n",
    "                    n = p.size(0)\n",
    "                    p.data[(n // 4):(n // 2)].fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    p.data.fill_(0)\n",
    "\n",
    "    def forward(self, feat):\n",
    "        numerical_embedding = self.numerical_linear(feat)\n",
    "        output,_ = self.rnn(numerical_embedding)\n",
    "        output = self.linear_out(output)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        preds = self.forward(X)\n",
    "\n",
    "        loss = self.loss_fn(preds, y)\n",
    "\n",
    "        self.train_metrics(preds, y)\n",
    "        self.log(\"loss\", loss, prog_bar=True, logger=True, on_epoch=True, on_step=True,)\n",
    "        self.log_dict(self.train_metrics, prog_bar=True, logger=True, on_epoch=True, on_step=True,)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        preds = self.forward(X)\n",
    "        \n",
    "        self.val_step_outputs.append(preds)\n",
    "        self.val_step_labels.append(y)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        preds = torch.cat(self.val_step_outputs)\n",
    "        labels = torch.cat(self.val_step_labels)\n",
    "        self.val_step_outputs.clear()\n",
    "        self.val_step_labels.clear()\n",
    "        loss = self.loss_fn(preds, labels)\n",
    "\n",
    "        self.valid_metrics(preds, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=False, logger=True, on_epoch=True, on_step=False,)\n",
    "        self.log_dict(self.valid_metrics, prog_bar=False, logger=True, on_epoch=True, on_step=False,)\n",
    "\n",
    "        # ログをprint\n",
    "        self.print_metric(preds, labels, \"valid\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=3, verbose=True)\n",
    "        return {\"optimizer\": optimizer, \n",
    "                \"lr_scheduler\": scheduler, \n",
    "                \"monitor\": \"val_loss\"}\n",
    "                \n",
    "    def print_metric(self, y_hat, y, train_or_valid=\"train\"):\n",
    "        \"\"\"\n",
    "        ログをprintする。次のepochが終わると上書きされてしまうので。\n",
    "        TODO: たぶんもっとマシな方法があるので探す。\n",
    "        \"\"\"\n",
    "        if train_or_valid == \"train\":\n",
    "            metrics = self.train_metrics\n",
    "        else:\n",
    "            metrics = self.valid_metrics\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "\n",
    "        print(f\"[epoch {self.trainer.current_epoch}] {train_or_valid}: \", end=\"\")\n",
    "        print(f\"{type(self.loss_fn).__name__}={loss:.4f}\", end=\", \")\n",
    "        for name in metrics:\n",
    "            v = metrics[name](y_hat, y)\n",
    "            print(f\"{name}={v:.4f}\", end=\", \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:14<00:00,  3.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3168"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(f\"{CFG['dataset']['step_csv_dir']}/*.csv\")\n",
    "dfs = []\n",
    "for file in tqdm(files):\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "train = pd.concat(dfs, axis=0).reset_index(drop=True)\n",
    "del dfs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "train[\"anglez\"] = (train[\"anglez\"] - ANGLEZ_MEAN) / ANGLEZ_STD\n",
    "train[\"enmo\"] = (train[\"enmo\"] - ENMO_MEAN) / ENMO_STD\n",
    "train[\"anglez_diff\"] = train[\"anglez\"].diff().fillna(0)\n",
    "train[\"enmo_diff\"] = train[\"enmo\"].diff().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>anglez</th>\n",
       "      <th>enmo</th>\n",
       "      <th>event</th>\n",
       "      <th>target</th>\n",
       "      <th>onset_target</th>\n",
       "      <th>wakeup_target</th>\n",
       "      <th>anglez_diff</th>\n",
       "      <th>enmo_diff</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-05T11:15:00-0500</td>\n",
       "      <td>2.747306</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-05T11:15:05-0500</td>\n",
       "      <td>2.747331</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-05T11:15:10-0500</td>\n",
       "      <td>2.747416</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-02-05T11:15:15-0500</td>\n",
       "      <td>2.747314</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-02-05T11:15:20-0500</td>\n",
       "      <td>2.747441</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      series_id  step                 timestamp    anglez      enmo event  \\\n",
       "0  af91d9a50547     0  2018-02-05T11:15:00-0500  2.747306 -0.405894   NaN   \n",
       "1  af91d9a50547     1  2018-02-05T11:15:05-0500  2.747331 -0.405894   NaN   \n",
       "2  af91d9a50547     2  2018-02-05T11:15:10-0500  2.747416 -0.405894   NaN   \n",
       "3  af91d9a50547     3  2018-02-05T11:15:15-0500  2.747314 -0.405894   NaN   \n",
       "4  af91d9a50547     4  2018-02-05T11:15:20-0500  2.747441 -0.405894   NaN   \n",
       "\n",
       "   target  onset_target  wakeup_target  anglez_diff  enmo_diff  fold  \n",
       "0       1           0.0            0.0     0.000000        0.0     3  \n",
       "1       1           0.0            0.0     0.000025        0.0     3  \n",
       "2       1           0.0            0.0     0.000084        0.0     3  \n",
       "3       1           0.0            0.0    -0.000101        0.0     3  \n",
       "4       1           0.0            0.0     0.000127        0.0     3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(127946340, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv splitとマージ\n",
    "cv_split = pd.read_csv(CFG['dataset']['cv_split_path'])\n",
    "train[\"fold\"] = train[\"series_id\"].map(cv_split.set_index(\"series_id\")[\"fold\"])\n",
    "display(train.head(5))\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:26<00:00, 10.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10000, 4), (10000, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SEQ_LEN ごとに分割\n",
    "dfs = []\n",
    "for series_id, df in tqdm(train.groupby(\"series_id\")):\n",
    "    df = df.sort_values(\"step\")\n",
    "\n",
    "    for start in range(0, len(df), SEQ_LEN // 2):\n",
    "        end = start + SEQ_LEN\n",
    "        if end > len(df):\n",
    "            end = len(df)\n",
    "            start = end - SEQ_LEN\n",
    "            assert start >= 0\n",
    "        dfs.append(df.iloc[start: end])\n",
    "gc.collect()\n",
    "\n",
    "features = Features()\n",
    "features.add_num_features([\"anglez\", \"enmo\"])\n",
    "features.add_num_features([\"anglez_diff\", \"enmo_diff\"])\n",
    "dataset_oof = ZzzDataset(dfs, 'train', features)\n",
    "feats, targets = dataset_oof[0]\n",
    "feats.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fold 0 ==\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b1cb15fb594bfe95186be480cef96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] valid: MSELoss=0.7172, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ca8ba4857f4c9691f4bf5a8af2a942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c76a68808d44e8877e399f9ee646dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] valid: MSELoss=0.2182, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3413a89e7d94bad9a4b7bebb8fa7875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] valid: MSELoss=0.1918, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c85bbc170047aa98e98a137486f7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] valid: MSELoss=0.1765, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4725cce5044fe7a0576e26435cea99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] valid: MSELoss=0.1726, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da6e5fa576c4d10952d2cf6dfe1cf54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] valid: MSELoss=0.1682, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df33ef55a91849e5a450a0bbc5b8cccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] valid: MSELoss=0.1697, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3460a785fa49ff9f24ae4bd061e5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] valid: MSELoss=0.1696, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad80590849b4d9f9ba8341f17e4f0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] valid: MSELoss=0.1658, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ac66be476a4a2ba5275e754aa574f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] valid: MSELoss=0.1692, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c009b07e8645bfb890706a1929a583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] valid: MSELoss=0.1672, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7c71b892044b188d539bc4fb1b62f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] valid: MSELoss=0.1718, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147071144b7847e58985dd4496becbf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11] valid: MSELoss=0.1776, \n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9eafde235ed427b869cb8abc540a6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12] valid: MSELoss=0.1765, \n"
     ]
    }
   ],
   "source": [
    "fold_oof_dfs = []\n",
    "for fold in range(5):\n",
    "    print(f\"== fold {fold} ==\")\n",
    "    \n",
    "    # 学習・評価データ\n",
    "    train_dfs = [df for df in dfs if df[\"fold\"].unique()[0] != fold]\n",
    "    valid_dfs = [df for df in dfs if df[\"fold\"].unique()[0] == fold]\n",
    "    train_dataset = ZzzDataset(train_dfs, mode=\"train\", features=features)\n",
    "    valid_dataset = ZzzDataset(valid_dfs, mode=\"train\", features=features)\n",
    "    data_module = MyLightningDataModule(train_dataset, valid_dataset, batch_size=64)\n",
    "\n",
    "    # モデル\n",
    "    model = ZzzGRUModule(lr=0.001, loss_fn=nn.MSELoss(), input_numerical_size=len(features.all_features()))\n",
    "    \n",
    "    # コールバック\n",
    "    cp_callback = ModelCheckpoint(\n",
    "        \"logs/\", \n",
    "        filename=f\"best_model_fold{fold}\",\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=1,\n",
    "        save_last=False,\n",
    "    )\n",
    "    es_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        patience=5,\n",
    "    )\n",
    "\n",
    "    # 学習\n",
    "    trainer = pl.Trainer(\n",
    "        callbacks=[cp_callback, es_callback],\n",
    "        )\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "    # 推論\n",
    "    model = ZzzGRUModule.load_from_checkpoint(\n",
    "        f\"logs/best_model_fold{fold}.ckpt\", \n",
    "        input_numerical_size=len(features.all_features()),\n",
    "        loss_fn=nn.BCEWithLogitsLoss()).to(\"cuda\")\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_module.val_dataloader():\n",
    "            pred = model(X.to(\"cuda\")).detach().cpu().numpy()\n",
    "            preds.append(pred)\n",
    "\n",
    "    oof_dfs = []\n",
    "    for pred, df in zip(np.vstack(preds), valid_dfs):\n",
    "        df[[\"wakeup_oof\", \"onset_oof\"]] = pred\n",
    "        oof_dfs.append(df)\n",
    "\n",
    "    oof_df = pd.concat(oof_dfs)\n",
    "    oof_df = oof_df.groupby([\"series_id\", \"step\"]).mean().reset_index().sort_values([\"series_id\", \"step\"])\n",
    "    fold_oof_dfs.append(oof_df)\n",
    "    break\n",
    "train = pd.concat(fold_oof_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "df = train[[\"series_id\", \"step\", \"wakeup_oof\"]].copy()\n",
    "df[\"event\"] = \"wakeup\"\n",
    "df[\"score\"] = df[\"wakeup_oof\"]\n",
    "dfs.append(df[['series_id', 'step', 'event', 'score']])\n",
    "\n",
    "df = train[[\"series_id\", \"step\", \"onset_oof\"]].copy()\n",
    "df[\"event\"] = \"onset\"\n",
    "df[\"score\"] = df[\"onset_oof\"]\n",
    "dfs.append(df[['series_id', 'step', 'event', 'score']])\n",
    "\n",
    "train = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51355080"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05168201471013189"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train[\"score\"]>0.1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2654134"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[train[\"score\"]>0.1].reset_index(drop=True)\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"score\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic-Range NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [27:26<00:00, 29.95s/it]   \n"
     ]
    }
   ],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "score2range = interp1d([-100, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 100], [0, 0, 12, 36, 60, 90, 120, 150, 180, 240, 300, 360, 360])\n",
    "range2score = interp1d([0, 12, 36, 60, 90, 120, 150, 180, 240, 300, 360], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "score2range(1.5)\n",
    "\n",
    "def process_group(df):\n",
    "    dfs = []\n",
    "    df = df.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "    used = np.zeros(len(df))\n",
    "    reduce_rate = np.ones(df[\"step\"].max() + 500)\n",
    "    for _ in range(min(len(df), 300)):\n",
    "        best_score = -1e10\n",
    "        best_idx = -1\n",
    "        best_step = -1\n",
    "        best_row = -1\n",
    "        for i, row in df.iterrows():\n",
    "            if used[i]:\n",
    "                continue\n",
    "            score = row[\"score\"] / reduce_rate[row[\"step\"]]\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_idx = i\n",
    "                best_step = row[\"step\"]\n",
    "                row[\"reduced_score\"] = score\n",
    "                best_row = row\n",
    "        dfs.append(best_row)\n",
    "        used[best_idx] = True\n",
    "\n",
    "        range_ = score2range(best_score)\n",
    "        for r in range(1, int(range_)):\n",
    "            reduce = range2score(range_ - r) + 1\n",
    "            reduce_rate[best_step + r] = max(reduce_rate[best_step + r], reduce)\n",
    "            if best_step - r >= 0:\n",
    "                reduce_rate[best_step - r] = max(reduce_rate[best_step - r], reduce)\n",
    "    return dfs\n",
    "\n",
    "groups = [group for _, group in train.groupby(\"series_id\")]\n",
    "with Pool(30) as p:  \n",
    "    results = list(tqdm(p.imap(process_group, groups), total=len(groups)))\n",
    "all_results = [item for sublist in results for item in sublist]\n",
    "sub = pd.DataFrame(all_results)\n",
    "sub[\"score\"] = sub[\"reduced_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.7394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "event   tolerance\n",
       "onset   12           0.222049\n",
       "        36           0.598432\n",
       "        60           0.717602\n",
       "        90           0.771063\n",
       "        120          0.799836\n",
       "        150          0.810719\n",
       "        180          0.818450\n",
       "        240          0.827256\n",
       "        300          0.830594\n",
       "        360          0.838627\n",
       "wakeup  12           0.289955\n",
       "        36           0.631051\n",
       "        60           0.729195\n",
       "        90           0.796990\n",
       "        120          0.826603\n",
       "        150          0.836177\n",
       "        180          0.841682\n",
       "        240          0.850561\n",
       "        300          0.871823\n",
       "        360          0.878447\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# スコア計算\n",
    "labels = pd.read_csv(f\"{CFG['dataset']['competition_dir']}/train_events.csv\").dropna()\n",
    "labels = labels[labels[\"series_id\"].isin(sub[\"series_id\"].unique())]\n",
    "score, ap_table = compute_comptetition_metric(labels, sub)\n",
    "\n",
    "print(f\"score: {score:.4f}\")\n",
    "display(ap_table)\n",
    "sub.to_csv(os.path.join(CFG[\"output_dir\"], \"submission_after_nms.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
