{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 00:52:11.797378: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-10-14 00:52:11.797661: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-10-14 00:52:11.797669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_081\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "from glob import glob\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import MetricCollection, MeanSquaredError\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "sys.path.append('/kaggle/src')\n",
    "from utils.metric import compute_comptetition_metric\n",
    "from utils.postprocess import post_process\n",
    "from utils.set_seed import seed_base_torch\n",
    "from utils.feature_contena import Features\n",
    "from utils.lightning_utils import MyLightningDataModule\n",
    "\n",
    "PACKAGE_DIR = Path(\"/kaggle/src\")\n",
    "CFG = yaml.safe_load(open(PACKAGE_DIR / \"config.yaml\", \"r\"))\n",
    "print(CFG[\"gru\"][\"execution\"][\"exp_id\"])\n",
    "\n",
    "CFG[\"output_dir\"] = f\"/kaggle/output/{CFG['gru']['execution']['exp_id']}\"\n",
    "!rm -r {CFG[\"output_dir\"]}\n",
    "os.makedirs(CFG[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "seed_base_torch(CFG[\"env\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANGLEZ_MEAN = -8.810\n",
    "ANGLEZ_STD = 35.52\n",
    "ENMO_MEAN = 0.04132\n",
    "ENMO_STD = 0.1018\n",
    "\n",
    "SEQ_LEN = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZzzDataset(Dataset):\n",
    "    def __init__(self, dfs: list[pd.DataFrame], mode: str, features: Features):\n",
    "        self.dfs = dfs\n",
    "        self.mode = mode\n",
    "        self.features = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dfs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        df = self.dfs[index]\n",
    "\n",
    "        feats = df[self.features.all_features()].values.astype(np.float32)\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            targets = df[[\"wakeup_target\", \"onset_target\"]].values.astype(np.float32)\n",
    "            return feats, targets\n",
    "        else:\n",
    "            return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZzzGRUModule(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self, \n",
    "            dropout=0.2,\n",
    "            input_numerical_size=2,\n",
    "            numeraical_linear_size = 64,\n",
    "            model_size = 128,\n",
    "            linear_out = 128,\n",
    "            out_size=2,\n",
    "            loss_fn=nn.CrossEntropyLoss(), \n",
    "            lr=0.001, \n",
    "            weight_decay=0\n",
    "        ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.numerical_linear  = nn.Sequential(\n",
    "                nn.Linear(input_numerical_size, numeraical_linear_size),\n",
    "                nn.LayerNorm(numeraical_linear_size)\n",
    "            )\n",
    "        \n",
    "        self.rnn = nn.GRU(numeraical_linear_size, model_size,\n",
    "                            num_layers = 2, \n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.linear_out  = nn.Sequential(\n",
    "            nn.Linear(model_size*2, linear_out),\n",
    "            nn.LayerNorm(linear_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(linear_out, out_size))\n",
    "        self._reinitialize()\n",
    "\n",
    "        self.loss_fn = loss_fn\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        self.train_metrics = MetricCollection([], prefix=\"\")\n",
    "        self.valid_metrics = MetricCollection([], prefix=\"val_\")\n",
    "        \n",
    "        self.val_step_outputs = []\n",
    "        self.val_step_labels = []\n",
    "\n",
    "\n",
    "    def _reinitialize(self):\n",
    "        \"\"\"\n",
    "        Tensorflow/Keras-like initialization\n",
    "        \"\"\"\n",
    "        for name, p in self.named_parameters():\n",
    "            if 'rnn' in name:\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(p.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    p.data.fill_(0)\n",
    "                    # Set forget-gate bias to 1\n",
    "                    n = p.size(0)\n",
    "                    p.data[(n // 4):(n // 2)].fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    p.data.fill_(0)\n",
    "\n",
    "    def forward(self, feat):\n",
    "        numerical_embedding = self.numerical_linear(feat)\n",
    "        output,_ = self.rnn(numerical_embedding)\n",
    "        output = self.linear_out(output)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        preds = self.forward(X)\n",
    "\n",
    "        loss = self.loss_fn(preds, y)\n",
    "\n",
    "        self.train_metrics(preds, y)\n",
    "        self.log(\"loss\", loss, prog_bar=True, logger=True, on_epoch=True, on_step=True,)\n",
    "        self.log_dict(self.train_metrics, prog_bar=True, logger=True, on_epoch=True, on_step=True,)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        preds = self.forward(X)\n",
    "        \n",
    "        self.val_step_outputs.append(preds)\n",
    "        self.val_step_labels.append(y)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        preds = torch.cat(self.val_step_outputs)\n",
    "        labels = torch.cat(self.val_step_labels)\n",
    "        self.val_step_outputs.clear()\n",
    "        self.val_step_labels.clear()\n",
    "        loss = self.loss_fn(preds, labels)\n",
    "\n",
    "        self.valid_metrics(preds, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=False, logger=True, on_epoch=True, on_step=False,)\n",
    "        self.log_dict(self.valid_metrics, prog_bar=False, logger=True, on_epoch=True, on_step=False,)\n",
    "\n",
    "        # ログをprint\n",
    "        self.print_metric(preds, labels, \"valid\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=3, verbose=True)\n",
    "        return {\"optimizer\": optimizer, \n",
    "                \"lr_scheduler\": scheduler, \n",
    "                \"monitor\": \"val_loss\"}\n",
    "                \n",
    "    def print_metric(self, y_hat, y, train_or_valid=\"train\"):\n",
    "        \"\"\"\n",
    "        ログをprintする。次のepochが終わると上書きされてしまうので。\n",
    "        TODO: たぶんもっとマシな方法があるので探す。\n",
    "        \"\"\"\n",
    "        if train_or_valid == \"train\":\n",
    "            metrics = self.train_metrics\n",
    "        else:\n",
    "            metrics = self.valid_metrics\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "\n",
    "        print(f\"[epoch {self.trainer.current_epoch}] {train_or_valid}: \", end=\"\")\n",
    "        print(f\"{type(self.loss_fn).__name__}={loss:.4f}\", end=\", \")\n",
    "        for name in metrics:\n",
    "            v = metrics[name](y_hat, y)\n",
    "            print(f\"{name}={v:.4f}\", end=\", \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:18<00:00,  3.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3045"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(f\"{CFG['dataset']['step_csv_dir']}/*.csv\")\n",
    "dfs = []\n",
    "for file in tqdm(files):\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "train = pd.concat(dfs, axis=0).reset_index(drop=True)\n",
    "del dfs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "train[\"anglez\"] = (train[\"anglez\"] - ANGLEZ_MEAN) / ANGLEZ_STD\n",
    "train[\"enmo\"] = (train[\"enmo\"] - ENMO_MEAN) / ENMO_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>anglez</th>\n",
       "      <th>enmo</th>\n",
       "      <th>event</th>\n",
       "      <th>target</th>\n",
       "      <th>onset_target</th>\n",
       "      <th>wakeup_target</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-05T11:15:00-0500</td>\n",
       "      <td>2.747306</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-05T11:15:05-0500</td>\n",
       "      <td>2.747331</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-05T11:15:10-0500</td>\n",
       "      <td>2.747416</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-02-05T11:15:15-0500</td>\n",
       "      <td>2.747314</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-02-05T11:15:20-0500</td>\n",
       "      <td>2.747441</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      series_id  step                 timestamp    anglez      enmo event  \\\n",
       "0  af91d9a50547     0  2018-02-05T11:15:00-0500  2.747306 -0.405894   NaN   \n",
       "1  af91d9a50547     1  2018-02-05T11:15:05-0500  2.747331 -0.405894   NaN   \n",
       "2  af91d9a50547     2  2018-02-05T11:15:10-0500  2.747416 -0.405894   NaN   \n",
       "3  af91d9a50547     3  2018-02-05T11:15:15-0500  2.747314 -0.405894   NaN   \n",
       "4  af91d9a50547     4  2018-02-05T11:15:20-0500  2.747441 -0.405894   NaN   \n",
       "\n",
       "   target  onset_target  wakeup_target  fold  \n",
       "0       1           0.0            0.0     3  \n",
       "1       1           0.0            0.0     3  \n",
       "2       1           0.0            0.0     3  \n",
       "3       1           0.0            0.0     3  \n",
       "4       1           0.0            0.0     3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(127946340, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv splitとマージ\n",
    "cv_split = pd.read_csv(CFG['dataset']['cv_split_path'])\n",
    "train[\"fold\"] = train[\"series_id\"].map(cv_split.set_index(\"series_id\")[\"fold\"])\n",
    "display(train.head(5))\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:20<00:00, 13.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((5000, 2), (5000, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SEQ_LEN ごとに分割\n",
    "dfs = []\n",
    "for series_id, df in tqdm(train.groupby(\"series_id\")):\n",
    "    df = df.sort_values(\"step\")\n",
    "\n",
    "    for start in range(0, len(df), SEQ_LEN // 2):\n",
    "        end = start + SEQ_LEN\n",
    "        if end > len(df):\n",
    "            end = len(df)\n",
    "            start = end - SEQ_LEN\n",
    "            assert start >= 0\n",
    "        dfs.append(df.iloc[start: end])\n",
    "gc.collect()\n",
    "\n",
    "features = Features()\n",
    "features.add_num_features([\"anglez\", \"enmo\"])\n",
    "dataset_oof = ZzzDataset(dfs, 'train', features)\n",
    "feats, targets = dataset_oof[0]\n",
    "feats.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'logs': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fold 0 ==\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acc856436f84150af8e79181ef282fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] valid: MSELoss=0.6836, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611f8a20f4e74969b88235a41c5ed761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90427d74755540b08475d322c7d4a2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] valid: MSELoss=0.2969, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0934f904a244d384d9877ac91aa0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] valid: MSELoss=0.2208, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1907fdada59c47f6981d41e37fdf2a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] valid: MSELoss=0.2088, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c10ce35a55496c9c37e9965ea5430d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] valid: MSELoss=0.2092, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b088c8e3360a48bf9ecf8503b277ffd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] valid: MSELoss=0.1985, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a6afe62da24e43b799d805d00dad3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] valid: MSELoss=0.2013, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586d7e72bdda4479b12bf052d7502b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] valid: MSELoss=0.2029, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37933ab7ea74307b8bc9c1750f5c43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] valid: MSELoss=0.2044, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094f303dec0c4071b9720c1ed74352f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] valid: MSELoss=0.2110, \n",
      "Epoch 00009: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a508790d586f4252afc564c05c980665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] valid: MSELoss=0.1985, \n"
     ]
    }
   ],
   "source": [
    "fold_oof_dfs = []\n",
    "for fold in range(5):\n",
    "    print(f\"== fold {fold} ==\")\n",
    "    \n",
    "    # 学習・評価データ\n",
    "    train_dfs = [df for df in dfs if df[\"fold\"].unique()[0] != fold]\n",
    "    valid_dfs = [df for df in dfs if df[\"fold\"].unique()[0] == fold]\n",
    "    train_dataset = ZzzDataset(train_dfs, mode=\"train\", features=features)\n",
    "    valid_dataset = ZzzDataset(valid_dfs, mode=\"train\", features=features)\n",
    "    data_module = MyLightningDataModule(train_dataset, valid_dataset, batch_size=64)\n",
    "\n",
    "    # モデル\n",
    "    model = ZzzGRUModule(lr=0.001, loss_fn=nn.MSELoss())\n",
    "    \n",
    "    # コールバック\n",
    "    cp_callback = ModelCheckpoint(\n",
    "        \"logs/\", \n",
    "        filename=f\"best_model_fold{fold}\",\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=1,\n",
    "        save_last=False,\n",
    "    )\n",
    "    es_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        patience=5,\n",
    "    )\n",
    "\n",
    "    # 学習\n",
    "    trainer = pl.Trainer(\n",
    "        callbacks=[cp_callback, es_callback],\n",
    "        )\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "    # 推論\n",
    "    model = ZzzGRUModule.load_from_checkpoint(\n",
    "        f\"logs/best_model_fold{fold}.ckpt\", loss_fn=nn.BCEWithLogitsLoss()).to(\"cuda\")\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_module.val_dataloader():\n",
    "            pred = model(X.to(\"cuda\")).detach().cpu().numpy()\n",
    "            preds.append(pred)\n",
    "\n",
    "    oof_dfs = []\n",
    "    for pred, df in zip(np.vstack(preds), valid_dfs):\n",
    "        df[[\"wakeup_oof\", \"onset_oof\"]] = pred\n",
    "        oof_dfs.append(df)\n",
    "\n",
    "    oof_df = pd.concat(oof_dfs)\n",
    "    oof_df = oof_df.groupby([\"series_id\", \"step\"]).mean().reset_index().sort_values([\"series_id\", \"step\"])\n",
    "    fold_oof_dfs.append(oof_df)\n",
    "    break\n",
    "train = pd.concat(fold_oof_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "df = train[[\"series_id\", \"step\", \"wakeup_oof\"]].copy()\n",
    "df[\"event\"] = \"wakeup\"\n",
    "df[\"score\"] = df[\"wakeup_oof\"]\n",
    "dfs.append(df[['series_id', 'step', 'event', 'score']])\n",
    "\n",
    "df = train[[\"series_id\", \"step\", \"onset_oof\"]].copy()\n",
    "df[\"event\"] = \"onset\"\n",
    "df[\"score\"] = df[\"onset_oof\"]\n",
    "dfs.append(df[['series_id', 'step', 'event', 'score']])\n",
    "\n",
    "train = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51355080"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07362874325188472"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train[\"score\"]>0.1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train[\"score\"]>0.1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGsCAYAAAAPJKchAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgaklEQVR4nO3de3BU9fnH8c8SwoZoggITwiVA1FruIVwN/BSYApGhOJm21IIOFIWZdhILppUBbSURJV4I4AiCVCXFNgVpB6yoyDYMpEgQCaQFqyjVggMkgEgCSbtss/v7w5oaSEJ2E3xOsu/XTP7Yk3POfpcHhvecvbkCgUBAAAAARtpYLwAAAIQ3YgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmGpRMVJYWKgpU6aoW7ducrlc2rJlS9DnCAQCWrp0qW699Va53W51795dTzzxRPMvFgAANEpb6wUEo7KyUklJSbrvvvv0ve99L6RzzJ07V9u3b9fSpUs1cOBAnTt3TufOnWvmlQIAgMZytdQvynO5XNq8ebPS0tJqtnm9Xj3yyCP6/e9/r/Pnz2vAgAF66qmnNHbsWEnSBx98oEGDBunw4cP69re/bbNwAABQS4t6muZqMjIyVFRUpA0bNuhvf/ubpk6dqjvvvFMff/yxJOn111/XTTfdpK1btyoxMVG9e/fW7NmzuTICAIChVhMjx48f17p167Rp0ybdfvvtuvnmm/WLX/xC//d//6d169ZJkj755BMdO3ZMmzZt0vr165WXl6fi4mL94Ac/MF49AADhq0W9ZqQhhw4dUnV1tW699dZa271erzp16iRJ8vv98nq9Wr9+fc1+L730koYOHaojR47w1A0AAAZaTYxcvHhRERERKi4uVkRERK3fXX/99ZKkrl27qm3btrWCpW/fvpK+vLJCjAAA8M1rNTGSnJys6upqnT59Wrfffnud+4wePVr/+c9/9I9//EM333yzJOmjjz6SJPXq1esbWysAAPifFvVumosXL+ro0aOSvoyPZcuWady4cerYsaN69uype++9V++8845yc3OVnJysM2fOqKCgQIMGDdLkyZPl9/s1fPhwXX/99VqxYoX8fr/S09MVGxur7du3Gz86AADCU4uKkZ07d2rcuHFXbJ85c6by8vLk8/n0+OOPa/369Tpx4oQ6d+6s2267TdnZ2Ro4cKAk6eTJk3rggQe0fft2XXfddZo0aZJyc3PVsWPHb/rhAAAAtbAYAQAArU+reWsvAABomYgRAABgqkW8m8bv9+vkyZOKiYmRy+WyXg4AAGiEQCCgCxcuqFu3bmrTpv7rHy0iRk6ePKmEhATrZQAAgBB89tln6tGjR72/bxExEhMTI+nLBxMbGxvSOXw+n7Zv366JEycqMjKyOZeHZsKMnI35OB8zcr5wm1FFRYUSEhJq/h+vT4uIka+emomNjW1SjERHRys2NjYs/gK0RMzI2ZiP8zEj5wvXGV3tJRa8gBUAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYCipGcnJyNHz4cMXExCguLk5paWk6cuRIg8fk5eXJ5XLV+omKimrSogEAQOsRVIzs2rVL6enp2rt3rzwej3w+nyZOnKjKysoGj4uNjdWpU6dqfo4dO9akRQMAgNYjqM8Z2bZtW63beXl5iouLU3Fxse644456j3O5XIqPjw9thQAAoFVr0oeelZeXS5I6duzY4H4XL15Ur1695Pf7NWTIEC1ZskT9+/evd3+v1yuv11tzu6KiQtKXHxbj8/lCWutXx4V6PK49ZuRszMf5mJHzhduMGvs4XYFAIBDKHfj9ft111106f/68du/eXe9+RUVF+vjjjzVo0CCVl5dr6dKlKiws1Pvvv1/v59RnZWUpOzv7iu35+fmKjo4OZbkAAOAbVlVVpenTp6u8vLzBT1APOUZ++tOf6q233tLu3bsb/PKby/l8PvXt21fTpk3T4sWL69ynrisjCQkJOnv2bJM+Dt7j8WjChAlh9RG8LQkzcjbm43zMyPnCbUYVFRXq3LnzVWMkpKdpMjIytHXrVhUWFgYVIpIUGRmp5ORkHT16tN593G633G53ncc2dXjNcQ5cW8zI2ZiP8zEj5wuXGTX2MQb1bppAIKCMjAxt3rxZO3bsUGJiYtALq66u1qFDh9S1a9egjwUAAK1PUFdG0tPTlZ+fr9dee00xMTEqLS2VJHXo0EHt27eXJM2YMUPdu3dXTk6OJOmxxx7TbbfdpltuuUXnz5/XM888o2PHjmn27NnN/FAAAEBLFFSMrF69WpI0duzYWtvXrVunH//4x5Kk48ePq02b/11w+eKLLzRnzhyVlpbqxhtv1NChQ7Vnzx7169evaStvJr0XvGG9hKD988nJ1ksAAKDZBBUjjXmt686dO2vdXr58uZYvXx7UogAAQPjgu2kAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYCipGcnJyNHz4cMXExCguLk5paWk6cuTIVY/btGmT+vTpo6ioKA0cOFBvvvlmyAsGAACtS1AxsmvXLqWnp2vv3r3yeDzy+XyaOHGiKisr6z1mz549mjZtmu6//34dPHhQaWlpSktL0+HDh5u8eAAA0PK1DWbnbdu21bqdl5enuLg4FRcX64477qjzmGeffVZ33nmnHnroIUnS4sWL5fF4tHLlSq1ZsybEZQMAgNYiqBi5XHl5uSSpY8eO9e5TVFSkzMzMWttSU1O1ZcuWeo/xer3yer01tysqKiRJPp9PPp8vpLV+ddzlx7sjAiGdz1KofwZOV9+M4AzMx/mYkfOF24wa+zhdgUAgpP+N/X6/7rrrLp0/f167d++ud7927drpN7/5jaZNm1az7fnnn1d2drbKysrqPCYrK0vZ2dlXbM/Pz1d0dHQoywUAAN+wqqoqTZ8+XeXl5YqNja13v5CvjKSnp+vw4cMNhkioFi5cWOtqSkVFhRISEjRx4sQGH0xDfD6fPB6PJkyYoMjIyJrtA7LebvJ6v2mHs1Ktl3BN1DcjOAPzcT5m5HzhNqOvntm4mpBiJCMjQ1u3blVhYaF69OjR4L7x8fFXXAEpKytTfHx8vce43W653e4rtkdGRjZ5eJefw1vtatL5LLT2v8DNMWdcO8zH+ZiR84XLjBr7GIN6N00gEFBGRoY2b96sHTt2KDEx8arHpKSkqKCgoNY2j8ejlJSUYO4aAAC0UkFdGUlPT1d+fr5ee+01xcTEqLS0VJLUoUMHtW/fXpI0Y8YMde/eXTk5OZKkuXPnasyYMcrNzdXkyZO1YcMG7d+/X2vXrm3mhwIAAFqioK6MrF69WuXl5Ro7dqy6du1a87Nx48aafY4fP65Tp07V3B41apTy8/O1du1aJSUl6Q9/+IO2bNmiAQMGNN+jAAAALVZQV0Ya88abnTt3XrFt6tSpmjp1ajB3BQAAwgTfTQMAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwFHSOFhYWaMmWKunXrJpfLpS1btjS4/86dO+Vyua74KS0tDXXNAACgFQk6RiorK5WUlKRVq1YFddyRI0d06tSpmp+4uLhg7xoAALRCbYM9YNKkSZo0aVLQdxQXF6cbbrgh6OMAAEDrFnSMhGrw4MHyer0aMGCAsrKyNHr06Hr39Xq98nq9NbcrKiokST6fTz6fL6T7/+q4y493RwRCOp+lUP8MnK6+GcEZmI/zMSPnC7cZNfZxugKBQMj/G7tcLm3evFlpaWn17nPkyBHt3LlTw4YNk9fr1YsvvqhXXnlF7777roYMGVLnMVlZWcrOzr5ie35+vqKjo0NdLgAA+AZVVVVp+vTpKi8vV2xsbL37XfMYqcuYMWPUs2dPvfLKK3X+vq4rIwkJCTp79myDD6YhPp9PHo9HEyZMUGRkZM32AVlvh3Q+S4ezUq2XcE3UNyM4A/NxPmbkfOE2o4qKCnXu3PmqMfKNPU3zdSNGjNDu3bvr/b3b7Zbb7b5ie2RkZJOHd/k5vNWuJp3PQmv/C9wcc8a1w3ycjxk5X7jMqLGP0eRzRkpKStS1a1eLuwYAAA4T9JWRixcv6ujRozW3P/30U5WUlKhjx47q2bOnFi5cqBMnTmj9+vWSpBUrVigxMVH9+/fXv//9b7344ovasWOHtm/f3nyPAgAAtFhBx8j+/fs1bty4mtuZmZmSpJkzZyovL0+nTp3S8ePHa35/6dIl/fznP9eJEycUHR2tQYMG6c9//nOtcwAAgPAVdIyMHTtWDb3mNS8vr9bt+fPna/78+UEvDAAAhAe+mwYAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAIApYgQAAJgiRgAAgCliBAAAmCJGAACAKWIEAACYIkYAAICpoGOksLBQU6ZMUbdu3eRyubRly5arHrNz504NGTJEbrdbt9xyi/Ly8kJYKgAAaI2CjpHKykolJSVp1apVjdr/008/1eTJkzVu3DiVlJRo3rx5mj17tt5+++2gFwsAAFqftsEeMGnSJE2aNKnR+69Zs0aJiYnKzc2VJPXt21e7d+/W8uXLlZqaGuzdAwCAViboGAlWUVGRxo8fX2tbamqq5s2bV+8xXq9XXq+35nZFRYUkyefzyefzhbSOr467/Hh3RCCk81kK9c/A6eqbEZyB+TgfM3K+cJtRYx/nNY+R0tJSdenSpda2Ll26qKKiQv/617/Uvn37K47JyclRdnb2Fdu3b9+u6OjoJq3H4/HUuv30iCadzsSbb75pvYRr6vIZwVmYj/MxI+cLlxlVVVU1ar9rHiOhWLhwoTIzM2tuV1RUKCEhQRMnTlRsbGxI5/T5fPJ4PJowYYIiIyNrtg/IanmvXTmc1Tqf3qpvRnAG5uN8zMj5wm1GXz2zcTXXPEbi4+NVVlZWa1tZWZliY2PrvCoiSW63W263+4rtkZGRTR7e5efwVruadD4Lrf0vcHPMGdcO83E+ZuR84TKjxj7Ga/45IykpKSooKKi1zePxKCUl5VrfNQAAaAGCjpGLFy+qpKREJSUlkr58625JSYmOHz8u6cunWGbMmFGz/09+8hN98sknmj9/vj788EM9//zzevXVV/Xggw82zyMAAAAtWtAxsn//fiUnJys5OVmSlJmZqeTkZD366KOSpFOnTtWEiSQlJibqjTfekMfjUVJSknJzc/Xiiy/ytl4AACAphNeMjB07VoFA/W+HrevTVceOHauDBw8Ge1cAACAM8N00AADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAVEgxsmrVKvXu3VtRUVEaOXKk9u3bV+++eXl5crlctX6ioqJCXjAAAGhdgo6RjRs3KjMzU4sWLdKBAweUlJSk1NRUnT59ut5jYmNjderUqZqfY8eONWnRAACg9Qg6RpYtW6Y5c+Zo1qxZ6tevn9asWaPo6Gi9/PLL9R7jcrkUHx9f89OlS5cmLRoAALQebYPZ+dKlSyouLtbChQtrtrVp00bjx49XUVFRvcddvHhRvXr1kt/v15AhQ7RkyRL179+/3v29Xq+8Xm/N7YqKCkmSz+eTz+cLZsk1vjru8uPdEYGQzmcp1D8Dp6tvRnAG5uN8zMj5wm1GjX2crkAg0Oj/jU+ePKnu3btrz549SklJqdk+f/587dq1S+++++4VxxQVFenjjz/WoEGDVF5erqVLl6qwsFDvv/++evToUef9ZGVlKTs7+4rt+fn5io6ObuxyAQCAoaqqKk2fPl3l5eWKjY2td7+groyEIiUlpVa4jBo1Sn379tULL7ygxYsX13nMwoULlZmZWXO7oqJCCQkJmjhxYoMPpiE+n08ej0cTJkxQZGRkzfYBWW+HdD5Lh7NSrZdwTdQ3IzgD83E+ZuR84Tajr57ZuJqgYqRz586KiIhQWVlZre1lZWWKj49v1DkiIyOVnJyso0eP1ruP2+2W2+2u89imDu/yc3irXU06n4XW/he4OeaMa4f5OB8zcr5wmVFjH2NQL2Bt166dhg4dqoKCgpptfr9fBQUFta5+NKS6ulqHDh1S165dg7lrAADQSgX9NE1mZqZmzpypYcOGacSIEVqxYoUqKys1a9YsSdKMGTPUvXt35eTkSJIee+wx3Xbbbbrlllt0/vx5PfPMMzp27Jhmz57dvI8EAAC0SEHHyN13360zZ87o0UcfVWlpqQYPHqxt27bVvF33+PHjatPmfxdcvvjiC82ZM0elpaW68cYbNXToUO3Zs0f9+vVrvkcBAABarJBewJqRkaGMjIw6f7dz585at5cvX67ly5eHcjcAACAM8N00AADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMXfNv7UXz673gDeslBO2fT062XgIAwKG4MgIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEy1tV4AwkPvBW9cdR93REBPj5AGZL0tb7XrG1jV1f3zycnWSwCAVo8rIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFJ/ACjSgMZ8c6zR8aiyAloYrIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAU76YBWplr9Q4gd0RAT4+QBmS9LW+1q1nPzTuAgPDGlREAAGCKGAEAAKaIEQAAYIoYAQAApngBKwBzfOw+EN64MgIAAExxZQQAQuDEqzlXe/s1V3PgVFwZAQAAprgyAgBhwolXc66GqznhgSsjAADAFDECAABMESMAAMAUrxkBADgWr3MJD1wZAQAApogRAABgKqQYWbVqlXr37q2oqCiNHDlS+/bta3D/TZs2qU+fPoqKitLAgQP15ptvhrRYAADQ+gQdIxs3blRmZqYWLVqkAwcOKCkpSampqTp9+nSd++/Zs0fTpk3T/fffr4MHDyotLU1paWk6fPhwkxcPAABavqBfwLps2TLNmTNHs2bNkiStWbNGb7zxhl5++WUtWLDgiv2fffZZ3XnnnXrooYckSYsXL5bH49HKlSu1Zs2aJi4fAABnaehFt1f7yH4r1i+6DSpGLl26pOLiYi1cuLBmW5s2bTR+/HgVFRXVeUxRUZEyMzNrbUtNTdWWLVvqvR+v1yuv11tzu7y8XJJ07tw5+Xy+YJZcw+fzqaqqSp9//rkiIyNrtrf9T2VI50Pza+sPqKrKr7a+Nqr2O+cfKb7EfJyPGTmfU2f0+eefX5PzXrhwQZIUCAQa3C+oGDl79qyqq6vVpUuXWtu7dOmiDz/8sM5jSktL69y/tLS03vvJyclRdnb2FdsTExODWS5aoOnWC0CDmI/zMSPnc+KMOude2/NfuHBBHTp0qPf3jvyckYULF9a6muL3+3Xu3Dl16tRJLldoJVlRUaGEhAR99tlnio2Nba6lohkxI2djPs7HjJwv3GYUCAR04cIFdevWrcH9goqRzp07KyIiQmVlZbW2l5WVKT4+vs5j4uPjg9pfktxut9xud61tN9xwQzBLrVdsbGxY/AVoyZiRszEf52NGzhdOM2roishXgno3Tbt27TR06FAVFBTUbPP7/SooKFBKSkqdx6SkpNTaX5I8Hk+9+wMAgPAS9NM0mZmZmjlzpoYNG6YRI0ZoxYoVqqysrHl3zYwZM9S9e3fl5ORIkubOnasxY8YoNzdXkydP1oYNG7R//36tXbu2eR8JAABokYKOkbvvvltnzpzRo48+qtLSUg0ePFjbtm2reZHq8ePH1abN/y64jBo1Svn5+frlL3+phx9+WN/61re0ZcsWDRgwoPkeRSO43W4tWrToiqd/4BzMyNmYj/MxI+djRnVzBa72fhsAAIBriO+mAQAApogRAABgihgBAACmiBEAAGAqbGJk1apV6t27t6KiojRy5Ejt27fPeknQlx/9P3z4cMXExCguLk5paWk6cuSI9bLQgCeffFIul0vz5s2zXgq+5sSJE7r33nvVqVMntW/fXgMHDtT+/futlwVJ1dXV+tWvfqXExES1b99eN998sxYvXnzV72sJJ2ERIxs3blRmZqYWLVqkAwcOKCkpSampqTp9+rT10sLerl27lJ6err1798rj8cjn82nixImqrOQLDJ3ovffe0wsvvKBBgwZZLwVf88UXX2j06NGKjIzUW2+9pb///e/Kzc3VjTfeaL00SHrqqae0evVqrVy5Uh988IGeeuopPf3003ruueesl+YYYfHW3pEjR2r48OFauXKlpC8/NTYhIUEPPPCAFixYYLw6fN2ZM2cUFxenXbt26Y477rBeDr7m4sWLGjJkiJ5//nk9/vjjGjx4sFasWGG9LEhasGCB3nnnHf3lL3+xXgrq8N3vflddunTRSy+9VLPt+9//vtq3b6/f/va3hitzjlZ/ZeTSpUsqLi7W+PHja7a1adNG48ePV1FRkeHKUJfy8nJJUseOHY1Xgsulp6dr8uTJtf4twRn+9Kc/adiwYZo6dari4uKUnJysX//619bLwn+NGjVKBQUF+uijjyRJf/3rX7V7925NmjTJeGXO4chv7W1OZ8+eVXV1dc0nxH6lS5cu+vDDD41Whbr4/X7NmzdPo0eP/sY/oRcN27Bhgw4cOKD33nvPeimowyeffKLVq1crMzNTDz/8sN577z397Gc/U7t27TRz5kzr5YW9BQsWqKKiQn369FFERISqq6v1xBNP6J577rFemmO0+hhBy5Genq7Dhw9r9+7d1kvB13z22WeaO3euPB6PoqKirJeDOvj9fg0bNkxLliyRJCUnJ+vw4cNas2YNMeIAr776qn73u98pPz9f/fv3V0lJiebNm6du3boxn/9q9THSuXNnRUREqKysrNb2srIyxcfHG60Kl8vIyNDWrVtVWFioHj16WC8HX1NcXKzTp09ryJAhNduqq6tVWFiolStXyuv1KiIiwnCF6Nq1q/r161drW9++ffXHP/7RaEX4uoceekgLFizQj370I0nSwIEDdezYMeXk5BAj/9XqXzPSrl07DR06VAUFBTXb/H6/CgoKlJKSYrgySFIgEFBGRoY2b96sHTt2KDEx0XpJuMx3vvMdHTp0SCUlJTU/w4YN0z333KOSkhJCxAFGjx59xVviP/roI/Xq1ctoRfi6qqqqWl8gK0kRERHy+/1GK3KeVn9lRJIyMzM1c+ZMDRs2TCNGjNCKFStUWVmpWbNmWS8t7KWnpys/P1+vvfaaYmJiVFpaKknq0KGD2rdvb7w6SFJMTMwVr+G57rrr1KlTJ17b4xAPPvigRo0apSVLluiHP/yh9u3bp7Vr12rt2rXWS4OkKVOm6IknnlDPnj3Vv39/HTx4UMuWLdN9991nvTTnCISJ5557LtCzZ89Au3btAiNGjAjs3bvXekkIBAKS6vxZt26d9dLQgDFjxgTmzp1rvQx8zeuvvx4YMGBAwO12B/r06RNYu3at9ZLwXxUVFYG5c+cGevbsGYiKigrcdNNNgUceeSTg9Xqtl+YYYfE5IwAAwLla/WtGAACAsxEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwBQxAgAATBEjAADAFDECAABMESMAAMAUMQIAAEwRIwAAwNT/A+D9dP2zXvHGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"score\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic-Range NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/55 [09:48<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_items\u001b[39m.\u001b[39;49mpopleft()\n\u001b[1;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/kaggle/train/gru.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6b6167676c655c5c6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d737461746573222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6b6167676c652f6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d7374617465732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/kaggle/train/gru.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m groups \u001b[39m=\u001b[39m [group \u001b[39mfor\u001b[39;00m _, group \u001b[39min\u001b[39;00m train\u001b[39m.\u001b[39mgroupby(\u001b[39m\"\u001b[39m\u001b[39mseries_id\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6b6167676c655c5c6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d737461746573222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6b6167676c652f6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d7374617465732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/kaggle/train/gru.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mwith\u001b[39;00m Pool(\u001b[39m30\u001b[39m) \u001b[39mas\u001b[39;00m p:  \n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6b6167676c655c5c6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d737461746573222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6b6167676c652f6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d7374617465732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/kaggle/train/gru.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(tqdm(p\u001b[39m.\u001b[39;49mimap(process_group, groups), total\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(groups)))\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6b6167676c655c5c6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d737461746573222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6b6167676c652f6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d7374617465732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/kaggle/train/gru.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m all_results \u001b[39m=\u001b[39m [item \u001b[39mfor\u001b[39;00m sublist \u001b[39min\u001b[39;00m results \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m sublist]\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6b6167676c655c5c6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d737461746573222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6b6167676c652f6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d7374617465732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/kaggle/train/gru.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m sub \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(all_results)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 861\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    862\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    863\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items\u001b[39m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "score2range = interp1d([-100, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 100], [0, 0, 12, 36, 60, 90, 120, 150, 180, 240, 300, 360, 360])\n",
    "range2score = interp1d([0, 12, 36, 60, 90, 120, 150, 180, 240, 300, 360], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "score2range(1.5)\n",
    "\n",
    "def process_group(df):\n",
    "    dfs = []\n",
    "    df = df.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "    used = np.zeros(len(df))\n",
    "    reduce_rate = np.ones(df[\"step\"].max() + 500)\n",
    "    for _ in range(min(len(df), 300)):\n",
    "        best_score = -1e10\n",
    "        best_idx = -1\n",
    "        best_step = -1\n",
    "        best_row = -1\n",
    "        for i, row in df.iterrows():\n",
    "            if used[i]:\n",
    "                continue\n",
    "            score = row[\"score\"] / reduce_rate[row[\"step\"]]\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_idx = i\n",
    "                best_step = row[\"step\"]\n",
    "                row[\"reduced_score\"] = score\n",
    "                best_row = row\n",
    "        dfs.append(best_row)\n",
    "        used[best_idx] = True\n",
    "\n",
    "        range_ = score2range(best_score)\n",
    "        for r in range(1, int(range_)):\n",
    "            reduce = range2score(range_ - r) + 1\n",
    "            reduce_rate[best_step + r] = max(reduce_rate[best_step + r], reduce)\n",
    "            if best_step - r >= 0:\n",
    "                reduce_rate[best_step - r] = max(reduce_rate[best_step - r], reduce)\n",
    "    return dfs\n",
    "\n",
    "groups = [group for _, group in train.groupby(\"series_id\")]\n",
    "with Pool(30) as p:  \n",
    "    results = list(tqdm(p.imap(process_group, groups), total=len(groups)))\n",
    "all_results = [item for sublist in results for item in sublist]\n",
    "sub = pd.DataFrame(all_results)\n",
    "sub[\"score\"] = sub[\"reduced_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スコア計算\n",
    "labels = pd.read_csv(f\"{CFG['dataset']['competition_dir']}/train_events.csv\").dropna()\n",
    "labels = labels[labels[\"series_id\"].isin(sub[\"series_id\"].unique())]\n",
    "score, ap_table = compute_comptetition_metric(labels, sub)\n",
    "\n",
    "print(f\"score: {score:.4f}\")\n",
    "display(ap_table)\n",
    "sub.to_csv(os.path.join(CFG[\"output_dir\"], \"submission_after_nms.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
