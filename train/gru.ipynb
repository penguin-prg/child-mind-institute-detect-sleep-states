{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-13 23:15:53.836040: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-10-13 23:15:53.837015: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-10-13 23:15:53.837023: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_081\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "from glob import glob\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import MetricCollection, MeanSquaredError\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "sys.path.append('/kaggle/src')\n",
    "from utils.metric import compute_comptetition_metric\n",
    "from utils.postprocess import post_process\n",
    "from utils.set_seed import seed_base_torch\n",
    "from utils.feature_contena import Features\n",
    "from utils.lightning_utils import MyLightningDataModule\n",
    "\n",
    "PACKAGE_DIR = Path(\"/kaggle/src\")\n",
    "CFG = yaml.safe_load(open(PACKAGE_DIR / \"config.yaml\", \"r\"))\n",
    "print(CFG[\"gru\"][\"execution\"][\"exp_id\"])\n",
    "\n",
    "CFG[\"output_dir\"] = f\"/kaggle/output/{CFG['gru']['execution']['exp_id']}\"\n",
    "!rm -r {CFG[\"output_dir\"]}\n",
    "os.makedirs(CFG[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "seed_base_torch(CFG[\"env\"][\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANGLEZ_MEAN = -8.810\n",
    "ANGLEZ_STD = 35.52\n",
    "ENMO_MEAN = 0.04132\n",
    "ENMO_STD = 0.1018\n",
    "\n",
    "SEQ_LEN = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZzzDataset(Dataset):\n",
    "    def __init__(self, dfs: list[pd.DataFrame], mode: str, features: Features):\n",
    "        self.dfs = dfs\n",
    "        self.mode = mode\n",
    "        self.features = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dfs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        df = self.dfs[index]\n",
    "\n",
    "        feats = df[self.features.all_features()].values.astype(np.float32)\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            targets = df[[\"wakeup_target\", \"onset_target\"]].values.astype(np.float32)\n",
    "            return feats, targets\n",
    "        else:\n",
    "            return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZzzGRUModule(pl.LightningModule):\n",
    "    def __init__(\n",
    "            self, \n",
    "            dropout=0.2,\n",
    "            input_numerical_size=2,\n",
    "            numeraical_linear_size = 64,\n",
    "            model_size = 128,\n",
    "            linear_out = 128,\n",
    "            out_size=2,\n",
    "            loss_fn=nn.CrossEntropyLoss(), \n",
    "            lr=0.001, \n",
    "            weight_decay=0\n",
    "        ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.numerical_linear  = nn.Sequential(\n",
    "                nn.Linear(input_numerical_size, numeraical_linear_size),\n",
    "                nn.LayerNorm(numeraical_linear_size)\n",
    "            )\n",
    "        \n",
    "        self.rnn = nn.GRU(numeraical_linear_size, model_size,\n",
    "                            num_layers = 2, \n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.linear_out  = nn.Sequential(\n",
    "            nn.Linear(model_size*2, linear_out),\n",
    "            nn.LayerNorm(linear_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(linear_out, out_size))\n",
    "        self._reinitialize()\n",
    "\n",
    "        self.loss_fn = loss_fn\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        self.train_metrics = MetricCollection([], prefix=\"\")\n",
    "        self.valid_metrics = MetricCollection([], prefix=\"val_\")\n",
    "        \n",
    "        self.val_step_outputs = []\n",
    "        self.val_step_labels = []\n",
    "\n",
    "\n",
    "    def _reinitialize(self):\n",
    "        \"\"\"\n",
    "        Tensorflow/Keras-like initialization\n",
    "        \"\"\"\n",
    "        for name, p in self.named_parameters():\n",
    "            if 'rnn' in name:\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(p.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    p.data.fill_(0)\n",
    "                    # Set forget-gate bias to 1\n",
    "                    n = p.size(0)\n",
    "                    p.data[(n // 4):(n // 2)].fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    p.data.fill_(0)\n",
    "\n",
    "    def forward(self, feat):\n",
    "        numerical_embedding = self.numerical_linear(feat)\n",
    "        output,_ = self.rnn(numerical_embedding)\n",
    "        output = self.linear_out(output)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        preds = self.forward(X)\n",
    "\n",
    "        loss = self.loss_fn(preds, y)\n",
    "\n",
    "        self.train_metrics(preds, y)\n",
    "        self.log(\"loss\", loss, prog_bar=True, logger=True, on_epoch=True, on_step=True,)\n",
    "        self.log_dict(self.train_metrics, prog_bar=True, logger=True, on_epoch=True, on_step=True,)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        preds = self.forward(X)\n",
    "        \n",
    "        self.val_step_outputs.append(preds)\n",
    "        self.val_step_labels.append(y)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        preds = torch.cat(self.val_step_outputs)\n",
    "        labels = torch.cat(self.val_step_labels)\n",
    "        self.val_step_outputs.clear()\n",
    "        self.val_step_labels.clear()\n",
    "        loss = self.loss_fn(preds, labels)\n",
    "\n",
    "        self.valid_metrics(preds, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=False, logger=True, on_epoch=True, on_step=False,)\n",
    "        self.log_dict(self.valid_metrics, prog_bar=False, logger=True, on_epoch=True, on_step=False,)\n",
    "\n",
    "        # ログをprint\n",
    "        self.print_metric(preds, labels, \"valid\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=3, verbose=True)\n",
    "        return {\"optimizer\": optimizer, \n",
    "                \"lr_scheduler\": scheduler, \n",
    "                \"monitor\": \"val_loss\"}\n",
    "                \n",
    "    def print_metric(self, y_hat, y, train_or_valid=\"train\"):\n",
    "        \"\"\"\n",
    "        ログをprintする。次のepochが終わると上書きされてしまうので。\n",
    "        TODO: たぶんもっとマシな方法があるので探す。\n",
    "        \"\"\"\n",
    "        if train_or_valid == \"train\":\n",
    "            metrics = self.train_metrics\n",
    "        else:\n",
    "            metrics = self.valid_metrics\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "\n",
    "        print(f\"[epoch {self.trainer.current_epoch}] {train_or_valid}: \", end=\"\")\n",
    "        print(f\"{type(self.loss_fn).__name__}={loss:.4f}\", end=\", \")\n",
    "        for name in metrics:\n",
    "            v = metrics[name](y_hat, y)\n",
    "            print(f\"{name}={v:.4f}\", end=\", \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:21<00:00,  3.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3230"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(f\"{CFG['dataset']['step_csv_dir']}/*.csv\")\n",
    "dfs = []\n",
    "for file in tqdm(files):\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "train = pd.concat(dfs, axis=0).reset_index(drop=True)\n",
    "del dfs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "train[\"anglez\"] = (train[\"anglez\"] - ANGLEZ_MEAN) / ANGLEZ_STD\n",
    "train[\"enmo\"] = (train[\"enmo\"] - ENMO_MEAN) / ENMO_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>anglez</th>\n",
       "      <th>enmo</th>\n",
       "      <th>event</th>\n",
       "      <th>target</th>\n",
       "      <th>onset_target</th>\n",
       "      <th>wakeup_target</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-05T11:15:00-0500</td>\n",
       "      <td>2.747306</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-05T11:15:05-0500</td>\n",
       "      <td>2.747331</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-05T11:15:10-0500</td>\n",
       "      <td>2.747416</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-02-05T11:15:15-0500</td>\n",
       "      <td>2.747314</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-02-05T11:15:20-0500</td>\n",
       "      <td>2.747441</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      series_id  step                 timestamp    anglez      enmo event  \\\n",
       "0  af91d9a50547     0  2018-02-05T11:15:00-0500  2.747306 -0.405894   NaN   \n",
       "1  af91d9a50547     1  2018-02-05T11:15:05-0500  2.747331 -0.405894   NaN   \n",
       "2  af91d9a50547     2  2018-02-05T11:15:10-0500  2.747416 -0.405894   NaN   \n",
       "3  af91d9a50547     3  2018-02-05T11:15:15-0500  2.747314 -0.405894   NaN   \n",
       "4  af91d9a50547     4  2018-02-05T11:15:20-0500  2.747441 -0.405894   NaN   \n",
       "\n",
       "   target  onset_target  wakeup_target  fold  \n",
       "0       1           0.0            0.0     3  \n",
       "1       1           0.0            0.0     3  \n",
       "2       1           0.0            0.0     3  \n",
       "3       1           0.0            0.0     3  \n",
       "4       1           0.0            0.0     3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(127946340, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv splitとマージ\n",
    "cv_split = pd.read_csv(CFG['dataset']['cv_split_path'])\n",
    "train[\"fold\"] = train[\"series_id\"].map(cv_split.set_index(\"series_id\")[\"fold\"])\n",
    "display(train.head(5))\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:23<00:00, 11.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1000, 2), (1000, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SEQ_LEN ごとに分割\n",
    "dfs = []\n",
    "for series_id, df in tqdm(train.groupby(\"series_id\")):\n",
    "    df = df.sort_values(\"step\")\n",
    "\n",
    "    for start in range(0, len(df), SEQ_LEN // 2):\n",
    "        end = start + SEQ_LEN\n",
    "        if end > len(df):\n",
    "            end = len(df)\n",
    "            start = end - SEQ_LEN\n",
    "            assert start >= 0\n",
    "        dfs.append(df.iloc[start: end])\n",
    "gc.collect()\n",
    "\n",
    "features = Features()\n",
    "features.add_num_features([\"anglez\", \"enmo\"])\n",
    "dataset_oof = ZzzDataset(dfs, 'train', features)\n",
    "feats, targets = dataset_oof[0]\n",
    "feats.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'logs': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fold 0 ==\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1420bfc0b6b4f3e91a44701e95b5019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] valid: MSELoss=0.7762, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd169b408f9448cbde0f9f24459a5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052e7a5650b14e8aa2ebe5c1d29ac691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] valid: MSELoss=0.3684, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e83bac0e0e459ca8a4f17914760c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] valid: MSELoss=0.3284, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b18e4f1b3c4b99b01458e78549d05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] valid: MSELoss=0.3198, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b91a798e654767bb5d2cda268b3aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] valid: MSELoss=0.2979, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e96290cd394718a4beb26be6e8c26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] valid: MSELoss=0.2997, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52eb1af9a2e34cef8fa0dd061c410ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] valid: MSELoss=0.2948, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0913c8229ec646e4a8a82ddd1d964250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] valid: MSELoss=0.2867, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07e803a452c4d1d9d99f88277614178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] valid: MSELoss=0.2901, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a80d69377484654a2a6fa861b553b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] valid: MSELoss=0.2914, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb3405eb72c44e3bf9f47bb5148c2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] valid: MSELoss=0.2967, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ebe1b2a56b45258ae1fd066248ecb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] valid: MSELoss=0.3024, \n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a2cf7f1bcf4738abe4b87f422df456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11] valid: MSELoss=0.3036, \n"
     ]
    }
   ],
   "source": [
    "fold_oof_dfs = []\n",
    "for fold in range(5):\n",
    "    print(f\"== fold {fold} ==\")\n",
    "    \n",
    "    # 学習・評価データ\n",
    "    train_dfs = [df for df in dfs if df[\"fold\"].unique()[0] != fold]\n",
    "    valid_dfs = [df for df in dfs if df[\"fold\"].unique()[0] == fold]\n",
    "    train_dataset = ZzzDataset(train_dfs, mode=\"train\", features=features)\n",
    "    valid_dataset = ZzzDataset(valid_dfs, mode=\"train\", features=features)\n",
    "    data_module = MyLightningDataModule(train_dataset, valid_dataset, batch_size=256)\n",
    "\n",
    "    # モデル\n",
    "    model = ZzzGRUModule(lr=0.001, loss_fn=nn.MSELoss())\n",
    "    \n",
    "    # コールバック\n",
    "    cp_callback = ModelCheckpoint(\n",
    "        \"logs/\", \n",
    "        filename=f\"best_model_fold{fold}\",\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=1,\n",
    "        save_last=False,\n",
    "    )\n",
    "    es_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        patience=5,\n",
    "    )\n",
    "\n",
    "    # 学習\n",
    "    trainer = pl.Trainer(\n",
    "        callbacks=[cp_callback, es_callback],\n",
    "        )\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "    # 推論\n",
    "    model = ZzzGRUModule.load_from_checkpoint(\n",
    "        f\"logs/best_model_fold{fold}.ckpt\", loss_fn=nn.BCEWithLogitsLoss()).to(\"cuda\")\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_module.val_dataloader():\n",
    "            pred = model(X.to(\"cuda\")).detach().cpu().numpy()\n",
    "            preds.append(pred)\n",
    "\n",
    "    oof_dfs = []\n",
    "    for pred, df in zip(np.vstack(preds), valid_dfs):\n",
    "        df[[\"wakeup_oof\", \"onset_oof\"]] = pred\n",
    "        oof_dfs.append(df)\n",
    "\n",
    "    oof_df = pd.concat(oof_dfs)\n",
    "    oof_df = oof_df.groupby([\"series_id\", \"step\"]).mean().reset_index().sort_values([\"series_id\", \"step\"])\n",
    "    fold_oof_dfs.append(oof_df)\n",
    "    break\n",
    "train = pd.concat(fold_oof_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "df = train[[\"series_id\", \"step\", \"wakeup_oof\"]].copy()\n",
    "df[\"event\"] = \"wakeup\"\n",
    "df[\"score\"] = df[\"wakeup_oof\"]\n",
    "dfs.append(df[['series_id', 'step', 'event', 'score']])\n",
    "\n",
    "df = train[[\"series_id\", \"step\", \"onset_oof\"]].copy()\n",
    "df[\"event\"] = \"onset\"\n",
    "df[\"score\"] = df[\"onset_oof\"]\n",
    "dfs.append(df[['series_id', 'step', 'event', 'score']])\n",
    "\n",
    "train = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51355080"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11140226049691676"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train[\"score\"]>0.1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train[\"score\"]>0.1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"score\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic-Range NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/55 [03:41<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_items\u001b[39m.\u001b[39;49mpopleft()\n\u001b[1;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/kaggle/train/gru.ipynb Cell 18\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6b6167676c655c5c6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d737461746573222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6b6167676c652f6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d7374617465732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/kaggle/train/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m groups \u001b[39m=\u001b[39m [group \u001b[39mfor\u001b[39;00m _, group \u001b[39min\u001b[39;00m train\u001b[39m.\u001b[39mgroupby(\u001b[39m\"\u001b[39m\u001b[39mseries_id\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6b6167676c655c5c6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d737461746573222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6b6167676c652f6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d7374617465732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/kaggle/train/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mwith\u001b[39;00m Pool(\u001b[39m30\u001b[39m) \u001b[39mas\u001b[39;00m p:  \n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6b6167676c655c5c6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d737461746573222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6b6167676c652f6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d7374617465732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/kaggle/train/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(tqdm(p\u001b[39m.\u001b[39;49mimap(process_group, groups), total\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(groups)))\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6b6167676c655c5c6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d737461746573222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6b6167676c652f6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d7374617465732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/kaggle/train/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m all_results \u001b[39m=\u001b[39m [item \u001b[39mfor\u001b[39;00m sublist \u001b[39min\u001b[39;00m results \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m sublist]\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a225c5c5c5c77736c2e6c6f63616c686f73745c5c5562756e74755c5c686f6d655c5c6b6167676c655c5c6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d737461746573222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6b6167676c652f6368696c642d6d696e642d696e737469747574652d6465746563742d736c6565702d7374617465732f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/kaggle/train/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m sub \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(all_results)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 861\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    862\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    863\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items\u001b[39m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "score2range = interp1d([-100, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 100], [0, 0, 12, 36, 60, 90, 120, 150, 180, 240, 300, 360, 360])\n",
    "range2score = interp1d([0, 12, 36, 60, 90, 120, 150, 180, 240, 300, 360], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "score2range(1.5)\n",
    "\n",
    "def process_group(df):\n",
    "    dfs = []\n",
    "    df = df.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "    used = np.zeros(len(df))\n",
    "    reduce_rate = np.ones(df[\"step\"].max() + 500)\n",
    "    for _ in range(min(len(df), 300)):\n",
    "        best_score = -1e10\n",
    "        best_idx = -1\n",
    "        best_step = -1\n",
    "        best_row = -1\n",
    "        for i, row in df.iterrows():\n",
    "            if used[i]:\n",
    "                continue\n",
    "            score = row[\"score\"] / reduce_rate[row[\"step\"]]\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_idx = i\n",
    "                best_step = row[\"step\"]\n",
    "                row[\"reduced_score\"] = score\n",
    "                best_row = row\n",
    "        dfs.append(best_row)\n",
    "        used[best_idx] = True\n",
    "\n",
    "        range_ = score2range(best_score)\n",
    "        for r in range(1, int(range_)):\n",
    "            reduce = range2score(range_ - r) + 1\n",
    "            reduce_rate[best_step + r] = max(reduce_rate[best_step + r], reduce)\n",
    "            if best_step - r >= 0:\n",
    "                reduce_rate[best_step - r] = max(reduce_rate[best_step - r], reduce)\n",
    "    return dfs\n",
    "\n",
    "groups = [group for _, group in train.groupby(\"series_id\")]\n",
    "with Pool(30) as p:  \n",
    "    results = list(tqdm(p.imap(process_group, groups), total=len(groups)))\n",
    "all_results = [item for sublist in results for item in sublist]\n",
    "sub = pd.DataFrame(all_results)\n",
    "sub[\"score\"] = sub[\"reduced_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スコア計算\n",
    "labels = pd.read_csv(f\"{CFG['dataset']['competition_dir']}/train_events.csv\").dropna()\n",
    "labels = labels[labels[\"series_id\"].isin(sub[\"series_id\"].unique())]\n",
    "score, ap_table = compute_comptetition_metric(labels, sub)\n",
    "\n",
    "print(f\"score: {score:.4f}\")\n",
    "display(ap_table)\n",
    "sub.to_csv(os.path.join(CFG[\"output_dir\"], \"submission_after_nms.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
