{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working\n",
    "%rm -rf /kaggle/working/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 08:03:38.887191: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-10-15 08:03:38.887745: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib\n",
      "2023-10-15 08:03:38.887756: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_085\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "from glob import glob\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import MetricCollection, MeanSquaredError\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "sys.path.append('/kaggle/src')\n",
    "from utils.metric import compute_comptetition_metric\n",
    "from utils.set_seed import seed_base_torch\n",
    "from utils.feature_contena import Features\n",
    "from utils.lightning_utils import MyLightningDataModule\n",
    "from utils.postprocess import dynamic_range_nms\n",
    "from multiprocessing import Pool\n",
    "from consts import ANGLEZ_MEAN, ANGLEZ_STD, ENMO_MEAN, ENMO_STD\n",
    "from torch_model.dataset import ZzzDataset\n",
    "from torch_model.gru_model import ZzzGRUModule\n",
    "\n",
    "PACKAGE_DIR = Path(\"/kaggle/src\")\n",
    "CFG = yaml.safe_load(open(PACKAGE_DIR / \"config.yaml\", \"r\"))\n",
    "print(CFG[\"gru\"][\"execution\"][\"exp_id\"])\n",
    "\n",
    "CFG[\"output_dir\"] = f\"/kaggle/output/{CFG['gru']['execution']['exp_id']}\"\n",
    "!rm -r {CFG[\"output_dir\"]}\n",
    "os.makedirs(CFG[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "seed_base_torch(CFG[\"env\"][\"seed\"])\n",
    "\n",
    "SEQ_LEN = CFG[\"gru\"][\"execution\"][\"seq_len\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [01:21<00:00,  3.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3231"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(f\"{CFG['dataset']['step_csv_dir']}/*.csv\")\n",
    "dfs = []\n",
    "for file in tqdm(files):\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "train = pd.concat(dfs, axis=0).reset_index(drop=True)\n",
    "del dfs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "train[\"anglez\"] = (train[\"anglez\"] - ANGLEZ_MEAN) / ANGLEZ_STD\n",
    "train[\"enmo\"] = (train[\"enmo\"] - ENMO_MEAN) / ENMO_STD\n",
    "train[\"anglez_diff\"] = train[\"anglez\"].diff().fillna(0)\n",
    "train[\"enmo_diff\"] = train[\"enmo\"].diff().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>anglez</th>\n",
       "      <th>enmo</th>\n",
       "      <th>event</th>\n",
       "      <th>target</th>\n",
       "      <th>onset_target</th>\n",
       "      <th>wakeup_target</th>\n",
       "      <th>anglez_diff</th>\n",
       "      <th>enmo_diff</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-02-05T11:15:00-0500</td>\n",
       "      <td>2.747306</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-05T11:15:05-0500</td>\n",
       "      <td>2.747331</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-05T11:15:10-0500</td>\n",
       "      <td>2.747416</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-02-05T11:15:15-0500</td>\n",
       "      <td>2.747314</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>af91d9a50547</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-02-05T11:15:20-0500</td>\n",
       "      <td>2.747441</td>\n",
       "      <td>-0.405894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      series_id  step                 timestamp    anglez      enmo event  \\\n",
       "0  af91d9a50547     0  2018-02-05T11:15:00-0500  2.747306 -0.405894   NaN   \n",
       "1  af91d9a50547     1  2018-02-05T11:15:05-0500  2.747331 -0.405894   NaN   \n",
       "2  af91d9a50547     2  2018-02-05T11:15:10-0500  2.747416 -0.405894   NaN   \n",
       "3  af91d9a50547     3  2018-02-05T11:15:15-0500  2.747314 -0.405894   NaN   \n",
       "4  af91d9a50547     4  2018-02-05T11:15:20-0500  2.747441 -0.405894   NaN   \n",
       "\n",
       "   target  onset_target  wakeup_target  anglez_diff  enmo_diff  fold  \n",
       "0       1           0.0            0.0     0.000000        0.0     3  \n",
       "1       1           0.0            0.0     0.000025        0.0     3  \n",
       "2       1           0.0            0.0     0.000084        0.0     3  \n",
       "3       1           0.0            0.0    -0.000101        0.0     3  \n",
       "4       1           0.0            0.0     0.000127        0.0     3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(127946340, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv splitとマージ\n",
    "cv_split = pd.read_csv(CFG['dataset']['cv_split_path'])\n",
    "train[\"fold\"] = train[\"series_id\"].map(cv_split.set_index(\"series_id\")[\"fold\"])\n",
    "display(train.head(5))\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:19<00:00, 14.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10000, 4), (10000, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SEQ_LEN ごとに分割\n",
    "dfs = []\n",
    "for series_id, df in tqdm(train.groupby(\"series_id\")):\n",
    "    df = df.sort_values(\"step\")\n",
    "\n",
    "    for start in range(0, len(df), SEQ_LEN // 2):\n",
    "        end = start + SEQ_LEN\n",
    "        if end > len(df):\n",
    "            end = len(df)\n",
    "            start = end - SEQ_LEN\n",
    "            assert start >= 0\n",
    "        dfs.append(df.iloc[start: end])\n",
    "gc.collect()\n",
    "\n",
    "features = Features()\n",
    "features.add_num_features([\"anglez\", \"enmo\"])\n",
    "features.add_num_features([\"anglez_diff\", \"enmo_diff\"])\n",
    "dataset_oof = ZzzDataset(dfs, 'train', features)\n",
    "feats, targets = dataset_oof[0]\n",
    "feats.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'logs': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== fold 0 ==\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fabe1e6f1340dcb3852bb8a5958045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] valid: MSELoss=0.5137, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899ec3f6b30f4f29b02a179172514f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64818acfc6074ba6b6c832ef9346580f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] valid: MSELoss=0.1725, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f06593b8ed4a9abb3e862394e746b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] valid: MSELoss=0.2042, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7f82fa57b247e49ebde52eae7464b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] valid: MSELoss=0.1699, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d98f983b65b4cb5893f3d9c7a8d2b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] valid: MSELoss=0.1564, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9149f8aded2442cea78fd593ed2e70b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] valid: MSELoss=0.1614, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3fb41134dbc49e8af1d5c0d7ef42bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] valid: MSELoss=0.1583, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6715c6da627040e2b2ee7e6c6ebfa308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] valid: MSELoss=0.1601, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697eb606804846ef90e55046efe2dfdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] valid: MSELoss=0.1582, \n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3adcca6c974ea9b8eb057fbdaa67f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] valid: MSELoss=0.1476, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87b9f8912d045e88c10fe00c5435dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] valid: MSELoss=0.1489, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1f675ac21742d2a05de90d75b71a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] valid: MSELoss=0.1513, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c34bfde89040e493d60c1b49db91d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11] valid: MSELoss=0.1546, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e122171f48b40949d6dd69d71317cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12] valid: MSELoss=0.1556, \n",
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8841365b31425b9fc3cf4d6f73f8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 13] valid: MSELoss=0.1556, \n",
      "== fold 1 ==\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d72374802ee40d5b17358f441ccf288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] valid: MSELoss=1.1903, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f096526fef42778d2eaa93fec122d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d007c84576084c4d837f0bd1d6a0b39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] valid: MSELoss=0.1595, \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:45\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/kaggle/src/torch_model/gru_model.py:111\u001b[0m, in \u001b[0;36mZzzGRUModule.forward\u001b[0;34m(self, feat)\u001b[0m\n\u001b[1;32m    108\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumerical_linear(feat)\n\u001b[1;32m    110\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwavenet(x)\n\u001b[1;32m    112\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    114\u001b[0m x, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrnn(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/kaggle/src/torch_model/gru_model.py:36\u001b[0m, in \u001b[0;36mWaveBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m res \u001b[39m=\u001b[39m x\n\u001b[1;32m     35\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_rates):\n\u001b[0;32m---> 36\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mtanh(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilter_convs[i](x)) \u001b[39m*\u001b[39m F\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgate_convs[i](x))\n\u001b[1;32m     37\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs[i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m](x)\n\u001b[1;32m     38\u001b[0m     \u001b[39m# x += res\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fold_oof_dfs = []\n",
    "for fold in range(5):\n",
    "    print(f\"== fold {fold} ==\")\n",
    "    \n",
    "    # 学習・評価データ\n",
    "    train_dfs = [df for df in dfs if df[\"fold\"].unique()[0] != fold]\n",
    "    valid_dfs = [df for df in dfs if df[\"fold\"].unique()[0] == fold]\n",
    "    train_dataset = ZzzDataset(train_dfs, mode=\"train\", features=features)\n",
    "    valid_dataset = ZzzDataset(valid_dfs, mode=\"train\", features=features)\n",
    "    data_module = MyLightningDataModule(train_dataset, valid_dataset, batch_size=32)\n",
    "\n",
    "    # モデル\n",
    "    model = ZzzGRUModule(lr=0.001, dropout=0.0, loss_fn=nn.MSELoss(), input_numerical_size=len(features.all_features()))\n",
    "    \n",
    "    # コールバック\n",
    "    cp_callback = ModelCheckpoint(\n",
    "        \"logs/\", \n",
    "        filename=f\"best_model_fold{fold}\",\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=1,\n",
    "        save_last=False,\n",
    "    )\n",
    "    es_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        patience=5,\n",
    "    )\n",
    "\n",
    "    # 学習\n",
    "    trainer = pl.Trainer(\n",
    "        callbacks=[cp_callback, es_callback],\n",
    "        )\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "    # 推論\n",
    "    model = ZzzGRUModule.load_from_checkpoint(\n",
    "        f\"logs/best_model_fold{fold}.ckpt\", \n",
    "        input_numerical_size=len(features.all_features()),\n",
    "        loss_fn=nn.BCEWithLogitsLoss()).to(\"cuda\")\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_module.val_dataloader():\n",
    "            pred = model(X.to(\"cuda\")).detach().cpu().numpy()\n",
    "            preds.append(pred)\n",
    "\n",
    "    oof_dfs = []\n",
    "    for pred, df in zip(np.vstack(preds), valid_dfs):\n",
    "        df[[\"wakeup_oof\", \"onset_oof\"]] = pred\n",
    "        oof_dfs.append(df)\n",
    "\n",
    "    oof_df = pd.concat(oof_dfs)\n",
    "    oof_df = oof_df.groupby([\"series_id\", \"step\"]).mean().reset_index().sort_values([\"series_id\", \"step\"])\n",
    "    fold_oof_dfs.append(oof_df[[\"series_id\", \"step\", \"wakeup_oof\", \"onset_oof\"]])\n",
    "\n",
    "    del model, preds, oof_df, oof_dfs\n",
    "    gc.collect()\n",
    "    break\n",
    "train = pd.concat(fold_oof_dfs)\n",
    "train.to_parquet(f\"{CFG['output_dir']}/oof.parquet\", index=False)\n",
    "del fold_oof_dfs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2492204"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs = []\n",
    "df = train[[\"series_id\", \"step\", \"wakeup_oof\"]].copy()\n",
    "df[\"event\"] = \"wakeup\"\n",
    "df[\"score\"] = df[\"wakeup_oof\"]\n",
    "dfs.append(df[['series_id', 'step', 'event', 'score']])\n",
    "\n",
    "df = train[[\"series_id\", \"step\", \"onset_oof\"]].copy()\n",
    "df[\"event\"] = \"onset\"\n",
    "df[\"score\"] = df[\"onset_oof\"]\n",
    "dfs.append(df[['series_id', 'step', 'event', 'score']])\n",
    "\n",
    "train = pd.concat(dfs)\n",
    "train = train[train[\"score\"]>0.1].reset_index(drop=True)\n",
    "train[\"score\"].hist()\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic-Range NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:05<00:00, 10.50it/s]\n"
     ]
    }
   ],
   "source": [
    "groups = [group for _, group in train.groupby(\"series_id\")]\n",
    "with Pool(30) as p:  \n",
    "    results = list(tqdm(p.imap(dynamic_range_nms, groups), total=len(groups)))\n",
    "sub = pd.concat(results)\n",
    "sub[\"score\"] = sub[\"reduced_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.7571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "event   tolerance\n",
       "onset   12           0.241206\n",
       "        36           0.639386\n",
       "        60           0.757494\n",
       "        90           0.810568\n",
       "        120          0.831142\n",
       "        150          0.841291\n",
       "        180          0.846411\n",
       "        240          0.855311\n",
       "        300          0.861947\n",
       "        360          0.865488\n",
       "wakeup  12           0.279990\n",
       "        36           0.654923\n",
       "        60           0.749210\n",
       "        90           0.804825\n",
       "        120          0.826811\n",
       "        150          0.839596\n",
       "        180          0.843324\n",
       "        240          0.851178\n",
       "        300          0.865848\n",
       "        360          0.875802\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# スコア計算\n",
    "labels = pd.read_csv(f\"{CFG['dataset']['competition_dir']}/train_events.csv\").dropna()\n",
    "labels = labels[labels[\"series_id\"].isin(sub[\"series_id\"].unique())]\n",
    "score, ap_table = compute_comptetition_metric(labels, sub)\n",
    "\n",
    "print(f\"score: {score:.4f}\")\n",
    "display(ap_table)\n",
    "sub.to_csv(os.path.join(CFG[\"output_dir\"], \"submission.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cp -r logs {CFG[\"output_dir\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
